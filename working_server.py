#!/usr/bin/env python3
"""
Working Mac Status PWA Server - Fixed Version
Âãï‰ΩúÁ¢∫Ë™çÊ∏à„Åø„ÅÆMac Status PWA„Çµ„Éº„Éê„ÉºÔºà‰øÆÊ≠£ÁâàÔºâ
"""

import asyncio
import json
import psutil
from datetime import datetime
from pathlib import Path
import os
import sys

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
import uvicorn

# Add backend directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

# Import ELYZA model interface
try:
    from elyza_model import ELYZAModelInterface, ModelConfig
    from prompt_generator import PromptGenerator
    ELYZA_AVAILABLE = True
except ImportError as e:
    print(f"Warning: ELYZA model not available: {e}")
    ELYZA_AVAILABLE = False

# Create FastAPI app
app = FastAPI(title="Mac Status PWA - Working")

# Mount static files
app.mount("/static", StaticFiles(directory="frontend"), name="static")

# Initialize ELYZA model
elyza_model = None
prompt_generator = None

async def initialize_elyza_model():
    """Initialize ELYZA model if available"""
    global elyza_model, prompt_generator
    
    if not ELYZA_AVAILABLE:
        print("ELYZA model not available, using fallback responses")
        return False
    
    try:
        # Model configuration
        model_path = "models/elyza7b/ELYZA-japanese-Llama-2-7b-instruct.Q4_0.gguf"
        
        if not os.path.exists(model_path):
            print(f"Model file not found: {model_path}")
            print("Using fallback responses")
            return False
        
        config = ModelConfig(
            model_path=model_path,
            n_ctx=1024,  # Reduced for better performance
            n_gpu_layers=-1,  # Use all Metal layers on M1
            n_threads=4,
            temperature=0.7,
            max_tokens=256
        )
        
        elyza_model = ELYZAModelInterface(config)
        success = await elyza_model.initialize_model()
        
        if success:
            prompt_generator = PromptGenerator()
            print("‚úÖ ELYZA model initialized successfully")
            return True
        else:
            print("‚ùå ELYZA model initialization failed")
            return False
            
    except Exception as e:
        print(f"Error initializing ELYZA model: {e}")
        return False

@app.get("/")
async def serve_pwa():
    """Serve the PWA main page"""
    try:
        with open("frontend/index.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content, status_code=200)
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>Mac Status PWA</h1><p>Frontend files not found</p>",
            status_code=200
        )

@app.get("/fixed")
async def serve_fixed_pwa():
    """Serve the fixed PWA version"""
    try:
        with open("fixed_index.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content, status_code=200)
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>Fixed Mac Status PWA</h1><p>Fixed version not found</p>",
            status_code=200
        )

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

def get_system_info():
    """Get current system information"""
    try:
        # CPU usage
        cpu_percent = psutil.cpu_percent(interval=0.1)
        
        # Memory usage
        memory = psutil.virtual_memory()
        
        # Disk usage
        disk = psutil.disk_usage('/')
        
        # Top processes
        processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            try:
                info = proc.info
                if info['cpu_percent'] is not None and info['cpu_percent'] > 0:
                    processes.append(info)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # Sort by CPU usage and get top 5
        processes = sorted(processes, key=lambda x: x['cpu_percent'] or 0, reverse=True)[:5]
        
        return {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": round(cpu_percent, 1),
            "memory_percent": round(memory.percent, 1),
            "memory_used": memory.used,
            "memory_total": memory.total,
            "disk_percent": round((disk.used / disk.total) * 100, 1),
            "disk_used": disk.used,
            "disk_total": disk.total,
            "processes": processes
        }
    except Exception as e:
        print(f"Error getting system info: {e}")
        return {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": 0,
            "memory_percent": 0,
            "memory_used": 0,
            "memory_total": 1,
            "disk_percent": 0,
            "disk_used": 0,
            "disk_total": 1,
            "processes": [],
            "error": str(e)
        }

# Store connected clients and conversation history
connected_clients = set()
conversation_history = {}  # websocket_id -> conversation data

class ConversationManager:
    def __init__(self):
        self.conversations = {}
    
    def get_conversation(self, client_id):
        if client_id not in self.conversations:
            self.conversations[client_id] = {
                'messages': [],
                'user_preferences': {
                    'politeness_level': 'polite',  # casual, polite, formal
                    'preferred_topics': [],
                    'question_patterns': {}
                },
                'session_start': datetime.now(),
                'last_interaction': datetime.now()
            }
        return self.conversations[client_id]
    
    def add_message(self, client_id, role, content):
        conv = self.get_conversation(client_id)
        conv['messages'].append({
            'role': role,
            'content': content,
            'timestamp': datetime.now()
        })
        conv['last_interaction'] = datetime.now()
        
        # Keep only last 20 messages to manage memory
        if len(conv['messages']) > 20:
            conv['messages'] = conv['messages'][-20:]
    
    def analyze_user_patterns(self, client_id, user_message):
        conv = self.get_conversation(client_id)
        
        # Track question patterns
        message_lower = user_message.lower()
        for keyword in ['cpu', '„É°„É¢„É™', '„Éá„Ç£„Çπ„ÇØ', '„Ç¢„Éó„É™', '„Éê„ÉÉ„ÉÜ„É™„Éº']:
            if keyword in message_lower:
                if keyword not in conv['user_preferences']['question_patterns']:
                    conv['user_preferences']['question_patterns'][keyword] = 0
                conv['user_preferences']['question_patterns'][keyword] += 1
        
        # Adjust politeness based on user's language style
        if any(word in message_lower for word in ['„Åè„Å†„Åï„ÅÑ', '„ÅäÈ°ò„ÅÑ', '„Åô„Åø„Åæ„Åõ„Çì']):
            conv['user_preferences']['politeness_level'] = 'formal'
        elif any(word in message_lower for word in ['Ôºü', 'ÔºÅ', '„Å†„Çà', '„Åò„ÇÉ„Çì']):
            conv['user_preferences']['politeness_level'] = 'casual'
    
    def get_context_for_response(self, client_id):
        conv = self.get_conversation(client_id)
        recent_messages = conv['messages'][-5:]  # Last 5 messages
        return {
            'recent_messages': recent_messages,
            'preferences': conv['user_preferences'],
            'session_duration': (datetime.now() - conv['session_start']).total_seconds() / 60
        }

conversation_manager = ConversationManager()

async def broadcast_system_status():
    """Broadcast system status to all connected clients"""
    while True:
        if connected_clients:
            system_info = get_system_info()
            message = {
                "type": "system_status_update",
                "data": system_info,
                "timestamp": datetime.now().isoformat()
            }
            
            # Send to all connected clients
            disconnected_clients = set()
            for websocket in connected_clients:
                try:
                    await websocket.send_text(json.dumps(message))
                except:
                    disconnected_clients.add(websocket)
            
            # Remove disconnected clients
            connected_clients -= disconnected_clients
        
        await asyncio.sleep(2)  # Update every 2 seconds

# Start background task
@app.on_event("startup")
async def startup_event():
    asyncio.create_task(broadcast_system_status())
    # Initialize ELYZA model in background
    asyncio.create_task(initialize_elyza_model())

def generate_fallback_response(user_message: str, system_info: dict) -> str:
    """Generate fallback response when ELYZA model is not available"""
    
    user_message_lower = user_message.lower()
    
    # Get current system metrics
    cpu_usage = system_info.get("cpu_percent", 0)
    memory_percent = system_info.get("memory_percent", 0)
    memory_used_gb = system_info.get("memory_used", 0) / (1024**3)
    memory_total_gb = system_info.get("memory_total", 1) / (1024**3)
    disk_percent = system_info.get("disk_percent", 0)
    disk_used_gb = system_info.get("disk_used", 0) / (1024**3)
    disk_total_gb = system_info.get("disk_total", 1) / (1024**3)
    top_processes = system_info.get("processes", [])[:3]
    
    # Enhanced keyword detection with more variations
    def contains_keywords(text, keywords):
        return any(keyword in text for keyword in keywords)
    
    # Enhanced keyword detection for more specific responses
    
    # Battery related questions with varied responses
    if contains_keywords(user_message_lower, ["„Éê„ÉÉ„ÉÜ„É™„Éº", "battery", "ÈõªÊ±†", "ÂÖÖÈõª"]):
        import random
        battery_responses = [
            "üîã Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®„Éê„ÉÉ„ÉÜ„É™„ÉºÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n„Éá„Çπ„ÇØ„Éà„ÉÉ„ÉóMac„ÅÆÂ†¥Âêà„ÄÅ„Éê„ÉÉ„ÉÜ„É™„ÉºÊÉÖÂ†±„ÅØÂà©Áî®„Åß„Åç„Åæ„Åõ„Çì„ÄÇMacBook„Çí„Åä‰Ωø„ÅÑ„ÅÆÂ†¥Âêà„ÅØ„ÄÅ„Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éê„ÉÉ„ÉÜ„É™„Éº„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ",
            "üîã „Éê„ÉÉ„ÉÜ„É™„ÉºÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÁèæÂú®ÈñãÁô∫‰∏≠„Åß„Åô„ÄÇ\n\nMacBook„Çí„Åä‰Ωø„ÅÑ„ÅÆÂ†¥Âêà„ÅØ„ÄÅ„É°„Éã„É•„Éº„Éê„Éº„ÅÆ„Éê„ÉÉ„ÉÜ„É™„Éº„Ç¢„Ç§„Ç≥„É≥„Çí„ÇØ„É™„ÉÉ„ÇØ„Åô„Çã„Åã„ÄÅ„Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éê„ÉÉ„ÉÜ„É™„Éº„ÅßË©≥Á¥∞„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ",
            "üîã ÁèæÂú®„ÄÅ„Éê„ÉÉ„ÉÜ„É™„ÉºÁõ£Ë¶ñÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\nÂÖÖÈõªÁä∂Ê≥Å„ÇíÁ¢∫Ë™ç„Åô„Çã„Å´„ÅØÔºö\n‚Ä¢ „É°„Éã„É•„Éº„Éê„Éº„ÅÆ„Éê„ÉÉ„ÉÜ„É™„Éº„Ç¢„Ç§„Ç≥„É≥\n‚Ä¢ „Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éê„ÉÉ„ÉÜ„É™„Éº\n‚Ä¢ „Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„É¢„Éã„Çø > „Ç®„Éç„É´„ÇÆ„Éº"
        ]
        return random.choice(battery_responses)
    
    # Running apps/processes
    elif contains_keywords(user_message_lower, ["„Ç¢„Éó„É™", "app", "„Éó„É≠„Çª„Çπ", "process", "ÂÆüË°å‰∏≠", "Ëµ∑Âãï‰∏≠", "Âãï„ÅÑ„Å¶„ÅÑ„Çã"]):
        response_text = "üì± **ÁèæÂú®ÂÆüË°å‰∏≠„ÅÆ‰∏ªË¶Å„Å™„Éó„É≠„Çª„Çπ:**\n\n"
        if top_processes:
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                mem_val = proc.get('memory_percent', 0) or 0
                response_text += f"**{i}. {proc['name']}**\n"
                response_text += f"   üñ•Ô∏è CPU: {cpu_val:.1f}% | üíæ „É°„É¢„É™: {mem_val:.1f}%\n\n"
        else:
            response_text += "„Éó„É≠„Çª„ÇπÊÉÖÂ†±„ÇíÂèñÂæó„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\n\n"
        
        response_text += f"üìä **„Ç∑„Çπ„ÉÜ„É†ÂÖ®‰Ωì„ÅÆ‰ΩøÁî®Áä∂Ê≥Å:**\n"
        response_text += f"üñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%"
        return response_text
    
    # Wi-Fi related questions with varied responses
    elif contains_keywords(user_message_lower, ["wifi", "wi-fi", "„ÉØ„Ç§„Éï„Ç°„Ç§", "ÁÑ°Á∑ö", "„Éç„ÉÉ„Éà", "„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà", "Êé•Á∂ö"]):
        import random
        wifi_responses = [
            f"üì∂ Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®Wi-FiÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊé•Á∂öÁä∂Ê≥Å„ÅØ„ÄÅ„Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
            f"üì∂ Wi-FiË©≥Á¥∞ÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÈñãÁô∫‰∫àÂÆö„Åß„Åô„ÄÇ\n\nÊé•Á∂öÁä∂Ê≥Å„ÇíÁ¢∫Ë™ç„Åô„Çã„Å´„ÅØÔºö\n‚Ä¢ „Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ\n‚Ä¢ „É°„Éã„É•„Éº„Éê„Éº„ÅÆWi-Fi„Ç¢„Ç§„Ç≥„É≥\n‚Ä¢ „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
            f"üì∂ ÁèæÂú®„ÄÅ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØË©≥Á¥∞Áõ£Ë¶ñÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\nWi-FiÊÉÖÂ†±„ÇíÁ¢∫Ë™ç„Åô„Çã„Å´„ÅØ„ÄÅ„Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö„ÅÆ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çª„ÇØ„Ç∑„Éß„É≥„Çí„ÅîÂà©Áî®„Åè„Å†„Åï„ÅÑ„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%"
        ]
        return random.choice(wifi_responses)
    
    # CPU related questions
    elif contains_keywords(user_message_lower, ["cpu", "„Éó„É≠„Çª„ÉÉ„Çµ", "‰ΩøÁî®Áéá", "Âá¶ÁêÜ"]):
        response_text = f"üñ•Ô∏è **ÁèæÂú®„ÅÆCPU‰ΩøÁî®Áéá„ÅØ {cpu_usage}% „Åß„Åô„ÄÇ**\n\n"
        if cpu_usage > 80:
            response_text += "‚ö†Ô∏è CPU‰ΩøÁî®Áéá„ÅåÈ´ò„ÇÅ„Åß„Åô„ÄÇÈáç„ÅÑÂá¶ÁêÜ„ÅåÂÆüË°å„Åï„Çå„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
        elif cpu_usage > 50:
            response_text += "üìä CPU‰ΩøÁî®Áéá„ÅØ‰∏≠Á®ãÂ∫¶„Åß„Åô„ÄÇÈÄöÂ∏∏„ÅÆÂãï‰ΩúÁØÑÂõ≤ÂÜÖ„Åß„Åô„ÄÇ"
        else:
            response_text += "‚úÖ CPU‰ΩøÁî®Áéá„ÅØ‰Ωé„Åè„ÄÅ„Ç∑„Çπ„ÉÜ„É†„Å´‰ΩôË£ï„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
        
        if top_processes:
            response_text += f"\n\n**‰∏ä‰Ωç„Éó„É≠„Çª„Çπ:**\n"
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                response_text += f"**{i}.** {proc['name']}: {cpu_val:.1f}%\n"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["„É°„É¢„É™", "memory", "ram", "‰ΩøÁî®Èáè"]):
        response_text = f"üíæ **ÁèæÂú®„ÅÆ„É°„É¢„É™‰ΩøÁî®Áä∂Ê≥Å:**\n\n"
        response_text += f"üìä ‰ΩøÁî®Áéá: **{memory_percent}%**\n"
        response_text += f"üìà ‰ΩøÁî®Èáè: **{memory_used_gb:.1f}GB** / {memory_total_gb:.1f}GB\n"
        response_text += f"üíø Á©∫„ÅçÂÆπÈáè: **{(memory_total_gb - memory_used_gb):.1f}GB**\n\n"
        
        if memory_percent > 85:
            response_text += "üî¥ „É°„É¢„É™‰ΩøÁî®Áéá„ÅåÈ´ò„ÅÑ„Åß„Åô„ÄÇ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñâ„Åò„Çã„Åì„Å®„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        elif memory_percent > 70:
            response_text += "üü° „É°„É¢„É™‰ΩøÁî®Áéá„Åå„ÇÑ„ÇÑÈ´ò„ÇÅ„Åß„Åô„ÄÇ"
        else:
            response_text += "üü¢ „É°„É¢„É™‰ΩøÁî®Áéá„ÅØÊ≠£Â∏∏ÁØÑÂõ≤ÂÜÖ„Åß„Åô„ÄÇ"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["„Éá„Ç£„Çπ„ÇØ", "disk", "storage", "ÂÆπÈáè"]):
        response_text = f"üíø **ÁèæÂú®„ÅÆ„Éá„Ç£„Çπ„ÇØ‰ΩøÁî®Áä∂Ê≥Å:**\n\n"
        response_text += f"üìä ‰ΩøÁî®Áéá: **{disk_percent}%**\n"
        response_text += f"üìà ‰ΩøÁî®Èáè: **{disk_used_gb:.0f}GB** / {disk_total_gb:.0f}GB\n"
        response_text += f"üíø Á©∫„ÅçÂÆπÈáè: **{(disk_total_gb - disk_used_gb):.0f}GB**\n\n"
        
        if disk_percent > 90:
            response_text += "üî¥ „Éá„Ç£„Çπ„ÇØÂÆπÈáè„Åå‰∏çË∂≥„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Éï„Ç°„Ç§„É´„ÅÆÊï¥ÁêÜ„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ"
        elif disk_percent > 80:
            response_text += "üü° „Éá„Ç£„Çπ„ÇØ‰ΩøÁî®Áéá„ÅåÈ´ò„ÇÅ„Åß„Åô„ÄÇ‰∏çË¶Å„Å™„Éï„Ç°„Ç§„É´„ÅÆÂâäÈô§„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        else:
            response_text += "üü¢ „Éá„Ç£„Çπ„ÇØÂÆπÈáè„Å´‰ΩôË£ï„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["„Ç∑„Çπ„ÉÜ„É†", "status", "ÂÖ®‰Ωì", "Áä∂Ê≥Å"]):
        response_text = f"üìä **„Ç∑„Çπ„ÉÜ„É†ÂÖ®‰Ωì„ÅÆÁä∂Ê≥Å**\n\n"
        response_text += f"üñ•Ô∏è CPU: **{cpu_usage}%**\n"
        response_text += f"üíæ „É°„É¢„É™: **{memory_percent}%** ({memory_used_gb:.1f}GB/{memory_total_gb:.1f}GB)\n"
        response_text += f"üíø „Éá„Ç£„Çπ„ÇØ: **{disk_percent}%** ({disk_used_gb:.0f}GB/{disk_total_gb:.0f}GB)\n\n"
        
        # Overall health assessment
        issues = []
        if cpu_usage > 80:
            issues.append("CPU‰ΩøÁî®Áéá„ÅåÈ´ò„ÅÑ")
        if memory_percent > 85:
            issues.append("„É°„É¢„É™‰∏çË∂≥")
        if disk_percent > 90:
            issues.append("„Éá„Ç£„Çπ„ÇØÂÆπÈáè‰∏çË∂≥")
        
        if issues:
            response_text += f"‚ö†Ô∏è **Ê≥®ÊÑè‰∫ãÈ†Ö:** {', '.join(issues)}"
        else:
            response_text += "‚úÖ **„Ç∑„Çπ„ÉÜ„É†„ÅØÊ≠£Â∏∏„Å´Âãï‰Ωú„Åó„Å¶„ÅÑ„Åæ„Åô**"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["„Åì„Çì„Å´„Å°„ÅØ", "hello", "„ÅØ„Åò„ÇÅ„Åæ„Åó„Å¶", "„Åä„ÅØ„Çà„ÅÜ", "„Åì„Çì„Å∞„Çì„ÅØ"]):
        response_text = f"üëã „Åì„Çì„Å´„Å°„ÅØÔºÅMac Status PWA„Å∏„Çà„ÅÜ„Åì„ÅùÔºÅ\n\n"
        response_text += f"ÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\n"
        response_text += f"üñ•Ô∏è CPU: {cpu_usage}%\n"
        response_text += f"üíæ „É°„É¢„É™: {memory_percent}%\n"
        response_text += f"üíø „Éá„Ç£„Çπ„ÇØ: {disk_percent}%\n\n"
        response_text += f"‰Ωï„Åã„ÅîË≥™Âïè„Åå„ÅÇ„Çå„Å∞„ÄÅ„ÅäÊ∞óËªΩ„Å´„ÅäËÅû„Åç„Åè„Å†„Åï„ÅÑÔºÅ"
        
        return response_text
    
    else:
        # Generate contextual responses based on question patterns
        import random
        
        # Check if it's a question about specific functionality not yet implemented
        if any(word in user_message_lower for word in ["Ê∏©Â∫¶", "temperature", "ÁÜ±", "„Éï„Ç°„É≥", "fan"]):
            import random
            temp_responses = [
                f"üå°Ô∏è Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®Ê∏©Â∫¶ÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n„Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£„Ç¢„Éó„É™ÔºàTG Pro„ÄÅMacs Fan ControlÁ≠âÔºâ„ÅßÊ∏©Â∫¶Áõ£Ë¶ñ„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
                f"üå°Ô∏è Ê∏©Â∫¶„Éª„Éï„Ç°„É≥Áõ£Ë¶ñÊ©üËÉΩ„ÅØ‰ªäÂæå„ÅÆÂÆüË£Ö‰∫àÂÆö„Åß„Åô„ÄÇ\n\nÁèæÂú®Âà©Áî®ÂèØËÉΩ„Å™Ê∏©Â∫¶Áõ£Ë¶ñÊñπÊ≥ïÔºö\n‚Ä¢ TG ProÔºàApp StoreÔºâ\n‚Ä¢ Macs Fan ControlÔºàÁÑ°ÊñôÔºâ\n‚Ä¢ iStat MenusÔºàÊúâÊñôÔºâ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
                f"üå°Ô∏è „Ç∑„Çπ„ÉÜ„É†Ê∏©Â∫¶„ÅÆÁõ£Ë¶ñÊ©üËÉΩ„ÅØÈñãÁô∫‰∏≠„Åß„Åô„ÄÇ\n\n‰ª£ÊõøÊâãÊÆµ„Å®„Åó„Å¶„ÄÅ„Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„É¢„Éã„Çø„ÅßCPU‰ΩøÁî®Áéá„Åã„ÇâË≤†Ëç∑Áä∂Ê≥Å„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%"
            ]
            return random.choice(temp_responses)
        
        elif any(word in user_message_lower for word in ["„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ", "network", "ÈÄö‰ø°", "ÈÄüÂ∫¶", "Â∏ØÂüü"]):
            import random
            network_responses = [
                f"üåê Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØË©≥Á¥∞ÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ‰ΩøÁî®Áä∂Ê≥Å„ÅØ„ÄÅ„Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„É¢„Éã„Çø > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çø„Éñ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
                f"üåê „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÈÄüÂ∫¶„Éª‰ΩøÁî®ÈáèÁõ£Ë¶ñÊ©üËÉΩ„ÅØÈñãÁô∫‰∫àÂÆö„Åß„Åô„ÄÇ\n\nÁèæÂú®„ÅÆÁ¢∫Ë™çÊñπÊ≥ïÔºö\n‚Ä¢ „Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„É¢„Éã„Çø > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ\n‚Ä¢ „Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ\n‚Ä¢ „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%"
            ]
            return random.choice(network_responses)
        
        # Generate varied helpful responses
        responses = [
            f"ü§ñ „ÅîË≥™Âïè„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å„Çí„ÅäÁü•„Çâ„Åõ„Åó„Åæ„ÅôÔºö\n\nüñ•Ô∏è CPU: {cpu_usage}%\nüíæ „É°„É¢„É™: {memory_percent}%\nüíø „Éá„Ç£„Çπ„ÇØ: {disk_percent}%\n\n„ÄåCPU„ÅÆË©≥Á¥∞„Äç„Äå„É°„É¢„É™„ÅÆÁä∂Ê≥Å„Äç„ÄåÂÆüË°å‰∏≠„ÅÆ„Ç¢„Éó„É™„Äç„Å™„Å©„Å®„ÅäËÅû„Åç„Åè„Å†„Åï„ÅÑ„ÄÇ",
            f"üìä „Ç∑„Çπ„ÉÜ„É†Áõ£Ë¶ñ‰∏≠„Åß„Åô„ÄÇÁèæÂú®„ÅÆÁä∂ÊÖãÔºö\n\nCPU‰ΩøÁî®Áéá: {cpu_usage}%\n„É°„É¢„É™‰ΩøÁî®Áéá: {memory_percent}%\n„Éá„Ç£„Çπ„ÇØ‰ΩøÁî®Áéá: {disk_percent}%\n\n‰ªñ„Å´‰Ωï„Åã„ÅäËÅû„Åç„Åó„Åü„ÅÑ„Åì„Å®„ÅØ„ÅÇ„Çä„Åæ„Åô„ÅãÔºü",
            f"üîç „Ç∑„Çπ„ÉÜ„É†„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Åæ„Åó„Åü„ÄÇ\n\n‚Ä¢ CPU: {cpu_usage}% {'(Ê≠£Â∏∏)' if cpu_usage < 70 else '(È´ò„ÇÅ)' if cpu_usage < 85 else '(Ê≥®ÊÑè)'}\n‚Ä¢ „É°„É¢„É™: {memory_percent}% {'(Ê≠£Â∏∏)' if memory_percent < 75 else '(È´ò„ÇÅ)' if memory_percent < 90 else '(Ê≥®ÊÑè)'}\n‚Ä¢ „Éá„Ç£„Çπ„ÇØ: {disk_percent}% {'(Ê≠£Â∏∏)' if disk_percent < 80 else '(È´ò„ÇÅ)' if disk_percent < 95 else '(Ê≥®ÊÑè)'}\n\nË©≥„Åó„ÅÑÊÉÖÂ†±„ÅåÂøÖË¶Å„Åß„Åó„Åü„Çâ„ÄÅÂÖ∑‰ΩìÁöÑ„Å´„ÅäËÅû„Åç„Åè„Å†„Åï„ÅÑ„ÄÇ",
            f"üíª Mac„ÅÆÁä∂ÊÖã„ÇíÁ¢∫Ë™ç„Åó„Åæ„Åó„Åü„ÄÇ\n\nCPU: {cpu_usage}%„ÄÅ„É°„É¢„É™: {memory_percent}%„ÄÅ„Éá„Ç£„Çπ„ÇØ: {disk_percent}%\n\n„Äå„Éê„ÉÉ„ÉÜ„É™„Éº„ÅØÔºü„Äç„ÄåWi-Fi„ÅØÔºü„Äç„ÄåÂÆüË°å‰∏≠„ÅÆ„Ç¢„Éó„É™„ÅØÔºü„Äç„Å™„Å©„Å®„ÅäËÅû„Åç„Åè„Å†„Åï„ÅÑ„ÄÇ"
        ]
        
        return random.choice(responses)

def get_time_based_greeting():
    """ÊôÇÈñìÂ∏Ø„Å´Âøú„Åò„ÅüÊå®Êã∂„ÇíÂèñÂæó"""
    current_hour = datetime.now().hour
    
    if 5 <= current_hour < 10:
        return "„Åä„ÅØ„Çà„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô"
    elif 10 <= current_hour < 18:
        return "„Åì„Çì„Å´„Å°„ÅØ"
    elif 18 <= current_hour < 22:
        return "„Åì„Çì„Å∞„Çì„ÅØ"
    else:
        return "„ÅäÁñ≤„Çå„Åï„Åæ„Åß„Åô"

def generate_personalized_response(user_message: str, system_info: dict, context: dict = None) -> str:
    """Generate personalized response based on user context and system info"""
    
    user_message_lower = user_message.lower()
    
    # Get current system metrics
    cpu_usage = system_info.get("cpu_percent", 0)
    memory_percent = system_info.get("memory_percent", 0)
    memory_used_gb = system_info.get("memory_used", 0) / (1024**3)
    memory_total_gb = system_info.get("memory_total", 1) / (1024**3)
    disk_percent = system_info.get("disk_percent", 0)
    disk_used_gb = system_info.get("disk_used", 0) / (1024**3)
    disk_total_gb = system_info.get("disk_total", 1) / (1024**3)
    top_processes = system_info.get("processes", [])[:3]
    
    # Get user context and preferences
    politeness_level = 'polite'
    recent_questions = []
    session_duration = 0
    
    if context:
        politeness_level = context.get('preferences', {}).get('politeness_level', 'polite')
        recent_questions = [msg['content'] for msg in context.get('recent_messages', []) if msg['role'] == 'user']
        session_duration = context.get('session_duration', 0)
    
    # Enhanced keyword detection with more variations
    def contains_keywords(text, keywords):
        return any(keyword in text for keyword in keywords)
    
    # Adjust response style based on politeness level
    def format_response(base_response, politeness_level):
        if politeness_level == 'casual':
            return base_response.replace('„Åß„Åô„ÄÇ', '„Å†„Çà„ÄÇ').replace('„Åæ„Åô„ÄÇ', '„Çã„Çà„ÄÇ').replace('„Åî„Åñ„ÅÑ„Åæ„Åô', '„ÅÇ„Çä„Åæ„Åô')
        elif politeness_level == 'formal':
            return base_response.replace('„Å†„Çà', '„Åß„Åô').replace('„Çã„Çà', '„Åæ„Åô')
        return base_response
    
    # Enhanced keyword detection for more specific responses
    
    # Battery related questions with varied responses
    if contains_keywords(user_message_lower, ["„Éê„ÉÉ„ÉÜ„É™„Éº", "battery", "ÈõªÊ±†", "ÂÖÖÈõª"]):
        import random
        battery_responses = [
            "üîã Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®„Éê„ÉÉ„ÉÜ„É™„ÉºÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n„Éá„Çπ„ÇØ„Éà„ÉÉ„ÉóMac„ÅÆÂ†¥Âêà„ÄÅ„Éê„ÉÉ„ÉÜ„É™„ÉºÊÉÖÂ†±„ÅØÂà©Áî®„Åß„Åç„Åæ„Åõ„Çì„ÄÇMacBook„Çí„Åä‰Ωø„ÅÑ„ÅÆÂ†¥Âêà„ÅØ„ÄÅ„Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éê„ÉÉ„ÉÜ„É™„Éº„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ",
            "üîã „Éê„ÉÉ„ÉÜ„É™„ÉºÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÁèæÂú®ÈñãÁô∫‰∏≠„Åß„Åô„ÄÇ\n\nMacBook„Çí„Åä‰Ωø„ÅÑ„ÅÆÂ†¥Âêà„ÅØ„ÄÅ„É°„Éã„É•„Éº„Éê„Éº„ÅÆ„Éê„ÉÉ„ÉÜ„É™„Éº„Ç¢„Ç§„Ç≥„É≥„Çí„ÇØ„É™„ÉÉ„ÇØ„Åô„Çã„Åã„ÄÅ„Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éê„ÉÉ„ÉÜ„É™„Éº„ÅßË©≥Á¥∞„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ",
            "üîã ÁèæÂú®„ÄÅ„Éê„ÉÉ„ÉÜ„É™„ÉºÁõ£Ë¶ñÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\nÂÖÖÈõªÁä∂Ê≥Å„ÇíÁ¢∫Ë™ç„Åô„Çã„Å´„ÅØÔºö\n‚Ä¢ „É°„Éã„É•„Éº„Éê„Éº„ÅÆ„Éê„ÉÉ„ÉÜ„É™„Éº„Ç¢„Ç§„Ç≥„É≥\n‚Ä¢ „Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éê„ÉÉ„ÉÜ„É™„Éº\n‚Ä¢ „Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„É¢„Éã„Çø > „Ç®„Éç„É´„ÇÆ„Éº"
        ]
        return random.choice(battery_responses)
    
    # Running apps/processes
    elif contains_keywords(user_message_lower, ["„Ç¢„Éó„É™", "app", "„Éó„É≠„Çª„Çπ", "process", "ÂÆüË°å‰∏≠", "Ëµ∑Âãï‰∏≠", "Âãï„ÅÑ„Å¶„ÅÑ„Çã"]):
        response_text = "üì± **ÁèæÂú®ÂÆüË°å‰∏≠„ÅÆ‰∏ªË¶Å„Å™„Éó„É≠„Çª„Çπ:**\n\n"
        if top_processes:
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                mem_val = proc.get('memory_percent', 0) or 0
                response_text += f"**{i}. {proc['name']}**\n"
                response_text += f"   üñ•Ô∏è CPU: {cpu_val:.1f}% | üíæ „É°„É¢„É™: {mem_val:.1f}%\n\n"
        else:
            response_text += "„Éó„É≠„Çª„ÇπÊÉÖÂ†±„ÇíÂèñÂæó„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\n\n"
        
        response_text += f"üìä **„Ç∑„Çπ„ÉÜ„É†ÂÖ®‰Ωì„ÅÆ‰ΩøÁî®Áä∂Ê≥Å:**\n"
        response_text += f"üñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%"
        return response_text
    
    # Wi-Fi related questions with varied responses
    elif contains_keywords(user_message_lower, ["wifi", "wi-fi", "„ÉØ„Ç§„Éï„Ç°„Ç§", "ÁÑ°Á∑ö", "„Éç„ÉÉ„Éà", "„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà", "Êé•Á∂ö"]):
        import random
        wifi_responses = [
            f"üì∂ Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®Wi-FiÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊé•Á∂öÁä∂Ê≥Å„ÅØ„ÄÅ„Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
            f"üì∂ Wi-FiË©≥Á¥∞ÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÈñãÁô∫‰∫àÂÆö„Åß„Åô„ÄÇ\n\nÊé•Á∂öÁä∂Ê≥Å„ÇíÁ¢∫Ë™ç„Åô„Çã„Å´„ÅØÔºö\n‚Ä¢ „Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ\n‚Ä¢ „É°„Éã„É•„Éº„Éê„Éº„ÅÆWi-Fi„Ç¢„Ç§„Ç≥„É≥\n‚Ä¢ „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
            f"üì∂ ÁèæÂú®„ÄÅ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØË©≥Á¥∞Áõ£Ë¶ñÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\nWi-FiÊÉÖÂ†±„ÇíÁ¢∫Ë™ç„Åô„Çã„Å´„ÅØ„ÄÅ„Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö„ÅÆ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çª„ÇØ„Ç∑„Éß„É≥„Çí„ÅîÂà©Áî®„Åè„Å†„Åï„ÅÑ„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%"
        ]
        return random.choice(wifi_responses)
    
    # CPU related questions
    elif contains_keywords(user_message_lower, ["cpu", "„Éó„É≠„Çª„ÉÉ„Çµ", "‰ΩøÁî®Áéá", "Âá¶ÁêÜ"]):
        response_text = f"üñ•Ô∏è **ÁèæÂú®„ÅÆCPU‰ΩøÁî®Áéá„ÅØ {cpu_usage}% „Åß„Åô„ÄÇ**\n\n"
        if cpu_usage > 80:
            response_text += "‚ö†Ô∏è CPU‰ΩøÁî®Áéá„ÅåÈ´ò„ÇÅ„Åß„Åô„ÄÇÈáç„ÅÑÂá¶ÁêÜ„ÅåÂÆüË°å„Åï„Çå„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
        elif cpu_usage > 50:
            response_text += "üìä CPU‰ΩøÁî®Áéá„ÅØ‰∏≠Á®ãÂ∫¶„Åß„Åô„ÄÇÈÄöÂ∏∏„ÅÆÂãï‰ΩúÁØÑÂõ≤ÂÜÖ„Åß„Åô„ÄÇ"
        else:
            response_text += "‚úÖ CPU‰ΩøÁî®Áéá„ÅØ‰Ωé„Åè„ÄÅ„Ç∑„Çπ„ÉÜ„É†„Å´‰ΩôË£ï„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
        
        if top_processes:
            response_text += f"\n\n**‰∏ä‰Ωç„Éó„É≠„Çª„Çπ:**\n"
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                response_text += f"**{i}.** {proc['name']}: {cpu_val:.1f}%\n"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["„É°„É¢„É™", "memory", "ram", "‰ΩøÁî®Èáè"]):
        response_text = f"üíæ **ÁèæÂú®„ÅÆ„É°„É¢„É™‰ΩøÁî®Áä∂Ê≥Å:**\n\n"
        response_text += f"üìä ‰ΩøÁî®Áéá: **{memory_percent}%**\n"
        response_text += f"üìà ‰ΩøÁî®Èáè: **{memory_used_gb:.1f}GB** / {memory_total_gb:.1f}GB\n"
        response_text += f"üíø Á©∫„ÅçÂÆπÈáè: **{(memory_total_gb - memory_used_gb):.1f}GB**\n\n"
        
        if memory_percent > 85:
            response_text += "üî¥ „É°„É¢„É™‰ΩøÁî®Áéá„ÅåÈ´ò„ÅÑ„Åß„Åô„ÄÇ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÈñâ„Åò„Çã„Åì„Å®„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        elif memory_percent > 70:
            response_text += "üü° „É°„É¢„É™‰ΩøÁî®Áéá„Åå„ÇÑ„ÇÑÈ´ò„ÇÅ„Åß„Åô„ÄÇ"
        else:
            response_text += "üü¢ „É°„É¢„É™‰ΩøÁî®Áéá„ÅØÊ≠£Â∏∏ÁØÑÂõ≤ÂÜÖ„Åß„Åô„ÄÇ"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["„Éá„Ç£„Çπ„ÇØ", "disk", "storage", "ÂÆπÈáè"]):
        response_text = f"üíø **ÁèæÂú®„ÅÆ„Éá„Ç£„Çπ„ÇØ‰ΩøÁî®Áä∂Ê≥Å:**\n\n"
        response_text += f"üìä ‰ΩøÁî®Áéá: **{disk_percent}%**\n"
        response_text += f"üìà ‰ΩøÁî®Èáè: **{disk_used_gb:.0f}GB** / {disk_total_gb:.0f}GB\n"
        response_text += f"üíø Á©∫„ÅçÂÆπÈáè: **{(disk_total_gb - disk_used_gb):.0f}GB**\n\n"
        
        if disk_percent > 90:
            response_text += "üî¥ „Éá„Ç£„Çπ„ÇØÂÆπÈáè„Åå‰∏çË∂≥„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Éï„Ç°„Ç§„É´„ÅÆÊï¥ÁêÜ„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ"
        elif disk_percent > 80:
            response_text += "üü° „Éá„Ç£„Çπ„ÇØ‰ΩøÁî®Áéá„ÅåÈ´ò„ÇÅ„Åß„Åô„ÄÇ‰∏çË¶Å„Å™„Éï„Ç°„Ç§„É´„ÅÆÂâäÈô§„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        else:
            response_text += "üü¢ „Éá„Ç£„Çπ„ÇØÂÆπÈáè„Å´‰ΩôË£ï„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["„Ç∑„Çπ„ÉÜ„É†", "status", "ÂÖ®‰Ωì", "Áä∂Ê≥Å"]):
        response_text = f"üìä **„Ç∑„Çπ„ÉÜ„É†ÂÖ®‰Ωì„ÅÆÁä∂Ê≥Å**\n\n"
        response_text += f"üñ•Ô∏è CPU: **{cpu_usage}%**\n"
        response_text += f"üíæ „É°„É¢„É™: **{memory_percent}%** ({memory_used_gb:.1f}GB/{memory_total_gb:.1f}GB)\n"
        response_text += f"üíø „Éá„Ç£„Çπ„ÇØ: **{disk_percent}%** ({disk_used_gb:.0f}GB/{disk_total_gb:.0f}GB)\n\n"
        
        # Overall health assessment
        issues = []
        if cpu_usage > 80:
            issues.append("CPU‰ΩøÁî®Áéá„ÅåÈ´ò„ÅÑ")
        if memory_percent > 85:
            issues.append("„É°„É¢„É™‰∏çË∂≥")
        if disk_percent > 90:
            issues.append("„Éá„Ç£„Çπ„ÇØÂÆπÈáè‰∏çË∂≥")
        
        if issues:
            response_text += f"‚ö†Ô∏è **Ê≥®ÊÑè‰∫ãÈ†Ö:** {', '.join(issues)}"
        else:
            response_text += "‚úÖ **„Ç∑„Çπ„ÉÜ„É†„ÅØÊ≠£Â∏∏„Å´Âãï‰Ωú„Åó„Å¶„ÅÑ„Åæ„Åô**"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["„Åì„Çì„Å´„Å°„ÅØ", "hello", "„ÅØ„Åò„ÇÅ„Åæ„Åó„Å¶", "„Åä„ÅØ„Çà„ÅÜ", "„Åì„Çì„Å∞„Çì„ÅØ"]):
        response_text = f"üëã „Åì„Çì„Å´„Å°„ÅØÔºÅMac Status PWA„Å∏„Çà„ÅÜ„Åì„ÅùÔºÅ\n\n"
        response_text += f"ÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\n"
        response_text += f"üñ•Ô∏è CPU: {cpu_usage}%\n"
        response_text += f"üíæ „É°„É¢„É™: {memory_percent}%\n"
        response_text += f"üíø „Éá„Ç£„Çπ„ÇØ: {disk_percent}%\n\n"
        response_text += f"‰Ωï„Åã„ÅîË≥™Âïè„Åå„ÅÇ„Çå„Å∞„ÄÅ„ÅäÊ∞óËªΩ„Å´„ÅäËÅû„Åç„Åè„Å†„Åï„ÅÑÔºÅ"
        
        return response_text
    
    else:
        # Generate contextual responses based on question patterns
        import random
        
        # Check if it's a question about specific functionality not yet implemented
        if any(word in user_message_lower for word in ["Ê∏©Â∫¶", "temperature", "ÁÜ±", "„Éï„Ç°„É≥", "fan"]):
            import random
            temp_responses = [
                f"üå°Ô∏è Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®Ê∏©Â∫¶ÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n„Çµ„Éº„Éâ„Éë„Éº„ÉÜ„Ç£„Ç¢„Éó„É™ÔºàTG Pro„ÄÅMacs Fan ControlÁ≠âÔºâ„ÅßÊ∏©Â∫¶Áõ£Ë¶ñ„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
                f"üå°Ô∏è Ê∏©Â∫¶„Éª„Éï„Ç°„É≥Áõ£Ë¶ñÊ©üËÉΩ„ÅØ‰ªäÂæå„ÅÆÂÆüË£Ö‰∫àÂÆö„Åß„Åô„ÄÇ\n\nÁèæÂú®Âà©Áî®ÂèØËÉΩ„Å™Ê∏©Â∫¶Áõ£Ë¶ñÊñπÊ≥ïÔºö\n‚Ä¢ TG ProÔºàApp StoreÔºâ\n‚Ä¢ Macs Fan ControlÔºàÁÑ°ÊñôÔºâ\n‚Ä¢ iStat MenusÔºàÊúâÊñôÔºâ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
                f"üå°Ô∏è „Ç∑„Çπ„ÉÜ„É†Ê∏©Â∫¶„ÅÆÁõ£Ë¶ñÊ©üËÉΩ„ÅØÈñãÁô∫‰∏≠„Åß„Åô„ÄÇ\n\n‰ª£ÊõøÊâãÊÆµ„Å®„Åó„Å¶„ÄÅ„Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„É¢„Éã„Çø„ÅßCPU‰ΩøÁî®Áéá„Åã„ÇâË≤†Ëç∑Áä∂Ê≥Å„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%"
            ]
            return random.choice(temp_responses)
        
        elif any(word in user_message_lower for word in ["„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ", "network", "ÈÄö‰ø°", "ÈÄüÂ∫¶", "Â∏ØÂüü"]):
            import random
            network_responses = [
                f"üåê Áî≥„ÅóË®≥„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åå„ÄÅÁèæÂú®„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØË©≥Á¥∞ÊÉÖÂ†±„ÅÆÂèñÂæóÊ©üËÉΩ„ÅØÂÆüË£Ö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ\n\n„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ‰ΩøÁî®Áä∂Ê≥Å„ÅØ„ÄÅ„Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„É¢„Éã„Çø > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Çø„Éñ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%",
                f"üåê „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÈÄüÂ∫¶„Éª‰ΩøÁî®ÈáèÁõ£Ë¶ñÊ©üËÉΩ„ÅØÈñãÁô∫‰∫àÂÆö„Åß„Åô„ÄÇ\n\nÁèæÂú®„ÅÆÁ¢∫Ë™çÊñπÊ≥ïÔºö\n‚Ä¢ „Ç¢„ÇØ„ÉÜ„Ç£„Éì„ÉÜ„Ç£„É¢„Éã„Çø > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ\n‚Ä¢ „Ç∑„Çπ„ÉÜ„É†Áí∞Â¢ÉË®≠ÂÆö > „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ\n‚Ä¢ „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£\n\nÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å:\nüñ•Ô∏è CPU: {cpu_usage}% | üíæ „É°„É¢„É™: {memory_percent}%"
            ]
            return random.choice(network_responses)
        
        # Generate varied helpful responses
        responses = [
            f"ü§ñ „ÅîË≥™Âïè„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇÁèæÂú®„ÅÆ„Ç∑„Çπ„ÉÜ„É†Áä∂Ê≥Å„Çí„ÅäÁü•„Çâ„Åõ„Åó„Åæ„ÅôÔºö\n\nüñ•Ô∏è CPU: {cpu_usage}%\nüíæ „É°„É¢„É™: {memory_percent}%\nüíø „Éá„Ç£„Çπ„ÇØ: {disk_percent}%\n\n„ÄåCPU„ÅÆË©≥Á¥∞„Äç„Äå„É°„É¢„É™„ÅÆÁä∂Ê≥Å„Äç„ÄåÂÆüË°å‰∏≠„ÅÆ„Ç¢„Éó„É™„Äç„Å™„Å©„Å®„ÅäËÅû„Åç„Åè„Å†„Åï„ÅÑ„ÄÇ",
            f"üìä „Ç∑„Çπ„ÉÜ„É†Áõ£Ë¶ñ‰∏≠„Åß„Åô„ÄÇÁèæÂú®„ÅÆÁä∂ÊÖãÔºö\n\nCPU‰ΩøÁî®Áéá: {cpu_usage}%\n„É°„É¢„É™‰ΩøÁî®Áéá: {memory_percent}%\n„Éá„Ç£„Çπ„ÇØ‰ΩøÁî®Áéá: {disk_percent}%\n\n‰ªñ„Å´‰Ωï„Åã„ÅäËÅû„Åç„Åó„Åü„ÅÑ„Åì„Å®„ÅØ„ÅÇ„Çä„Åæ„Åô„ÅãÔºü",
            f"üîç „Ç∑„Çπ„ÉÜ„É†„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Åæ„Åó„Åü„ÄÇ\n\n‚Ä¢ CPU: {cpu_usage}% {'(Ê≠£Â∏∏)' if cpu_usage < 70 else '(È´ò„ÇÅ)' if cpu_usage < 85 else '(Ê≥®ÊÑè)'}\n‚Ä¢ „É°„É¢„É™: {memory_percent}% {'(Ê≠£Â∏∏)' if memory_percent < 75 else '(È´ò„ÇÅ)' if memory_percent < 90 else '(Ê≥®ÊÑè)'}\n‚Ä¢ „Éá„Ç£„Çπ„ÇØ: {disk_percent}% {'(Ê≠£Â∏∏)' if disk_percent < 80 else '(È´ò„ÇÅ)' if disk_percent < 95 else '(Ê≥®ÊÑè)'}\n\nË©≥„Åó„ÅÑÊÉÖÂ†±„ÅåÂøÖË¶Å„Åß„Åó„Åü„Çâ„ÄÅÂÖ∑‰ΩìÁöÑ„Å´„ÅäËÅû„Åç„Åè„Å†„Åï„ÅÑ„ÄÇ",
            f"üíª Mac„ÅÆÁä∂ÊÖã„ÇíÁ¢∫Ë™ç„Åó„Åæ„Åó„Åü„ÄÇ\n\nCPU: {cpu_usage}%„ÄÅ„É°„É¢„É™: {memory_percent}%„ÄÅ„Éá„Ç£„Çπ„ÇØ: {disk_percent}%\n\n„Äå„Éê„ÉÉ„ÉÜ„É™„Éº„ÅØÔºü„Äç„ÄåWi-Fi„ÅØÔºü„Äç„ÄåÂÆüË°å‰∏≠„ÅÆ„Ç¢„Éó„É™„ÅØÔºü„Äç„Å™„Å©„Å®„ÅäËÅû„Åç„Åè„Å†„Åï„ÅÑ„ÄÇ"
        ]
        
        return random.choice(responses)

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time communication"""
    await websocket.accept()
    connected_clients.add(websocket)
    print(f"WebSocket client connected. Total clients: {len(connected_clients)}")
    
    # Send initial system status
    try:
        system_info = get_system_info()
        initial_message = {
            "type": "system_status_response",
            "data": {
                "system_status": system_info
            },
            "timestamp": datetime.now().isoformat()
        }
        await websocket.send_text(json.dumps(initial_message))
    except Exception as e:
        print(f"Error sending initial status: {e}")
    
    try:
        while True:
            # Receive message from client
            data = await websocket.receive_text()
            print(f"Received: {data}")
            
            try:
                message = json.loads(data)
                message_type = message.get("type", "")
                
                if message_type == "ping":
                    # Respond to ping
                    response = {
                        "type": "pong",
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                elif message_type == "system_status_request":
                    # Get system information
                    system_info = get_system_info()
                    response = {
                        "type": "system_status_response",
                        "data": {
                            "system_status": system_info
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                elif message_type == "chat_message":
                    # Enhanced chat response
                    # Handle both direct message and nested data.message formats
                    user_message = ""
                    if "data" in message and isinstance(message["data"], dict):
                        user_message = message["data"].get("message", "")
                    else:
                        user_message = message.get("message", "")
                    
                    print(f"üîç Processing chat message: '{user_message}'")
                    system_info = get_system_info()
                    
                    response_text = None
                    
                    # Try to use ELYZA model first
                    if elyza_model and elyza_model.is_initialized and prompt_generator:
                        try:
                            # Generate prompt with system context
                            prompt = prompt_generator.generate_system_status_prompt(
                                user_query=user_message,
                                system_metrics={
                                    'cpu_percent': system_info.get("cpu_percent", 0),
                                    'memory_percent': system_info.get("memory_percent", 0),
                                    'memory_used_gb': system_info.get("memory_used", 0) / (1024**3),
                                    'memory_total_gb': system_info.get("memory_total", 1) / (1024**3),
                                    'disk_percent': system_info.get("disk_percent", 0),
                                    'disk_used_gb': system_info.get("disk_used", 0) / (1024**3),
                                    'disk_total_gb': system_info.get("disk_total", 1) / (1024**3),
                                    'top_processes': system_info.get("processes", [])[:3]
                                }
                            )
                            
                            # Get response from ELYZA model
                            model_response = await elyza_model.generate_response(prompt)
                            if model_response and model_response.content.strip():
                                response_text = model_response.content.strip()
                                print(f"‚úÖ ELYZA response generated: {len(response_text)} chars")
                            else:
                                print("‚ö†Ô∏è ELYZA returned empty response, using fallback")
                                
                        except Exception as e:
                            print(f"‚ùå ELYZA model error: {e}")
                    
                    # If ELYZA model failed or not available, use fallback responses
                    if not response_text:
                        response_text = generate_fallback_response(user_message, system_info)
                        print(f"‚úÖ Fallback response generated for '{user_message}': {len(response_text)} chars")
                        print(f"üìù Response preview: {response_text[:50]}...")
                    
                    response = {
                        "type": "chat_response",
                        "data": {
                            "message": response_text
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                else:
                    # Unknown message type
                    response = {
                        "type": "error",
                        "data": {
                            "message": f"Unknown message type: {message_type}"
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                    
            except json.JSONDecodeError:
                # Invalid JSON
                response = {
                    "type": "error",
                    "data": {
                        "message": "Invalid JSON format"
                    },
                    "timestamp": datetime.now().isoformat()
                }
                await websocket.send_text(json.dumps(response))
                
    except WebSocketDisconnect:
        connected_clients.discard(websocket)
        print(f"WebSocket client disconnected. Total clients: {len(connected_clients)}")

if __name__ == "__main__":
    print("üöÄ Starting Mac Status PWA Server (Fixed Version)")
    print("ELYZA model available:", ELYZA_AVAILABLE)
    uvicorn.run(app, host="0.0.0.0", port=8002)