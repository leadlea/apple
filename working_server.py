#!/usr/bin/env python3
"""
Working Mac Status PWA Server - Fixed Version
å‹•ä½œç¢ºèªæ¸ˆã¿ã®Mac Status PWAã‚µãƒ¼ãƒãƒ¼ï¼ˆä¿®æ­£ç‰ˆï¼‰
"""

import asyncio
import json
import psutil
from datetime import datetime
from pathlib import Path
import os
import sys

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
import uvicorn

# Add backend directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

# Import ELYZA model interface
try:
    from elyza_model import ELYZAModelInterface, ModelConfig
    from prompt_generator import PromptGenerator
    ELYZA_AVAILABLE = True
except ImportError as e:
    print(f"Warning: ELYZA model not available: {e}")
    ELYZA_AVAILABLE = False

# Create FastAPI app
app = FastAPI(title="Mac Status PWA - Working")

# Mount static files
app.mount("/static", StaticFiles(directory="frontend"), name="static")

# Initialize ELYZA model
elyza_model = None
prompt_generator = None

async def initialize_elyza_model():
    """Initialize ELYZA model if available"""
    global elyza_model, prompt_generator
    
    if not ELYZA_AVAILABLE:
        print("ELYZA model not available, using fallback responses")
        return False
    
    try:
        # Model configuration
        model_path = "models/elyza7b/ELYZA-japanese-Llama-2-7b-instruct.Q4_0.gguf"
        
        if not os.path.exists(model_path):
            print(f"Model file not found: {model_path}")
            print("Using fallback responses")
            return False
        
        config = ModelConfig(
            model_path=model_path,
            n_ctx=1024,  # Reduced for better performance
            n_gpu_layers=-1,  # Use all Metal layers on M1
            n_threads=4,
            temperature=0.7,
            max_tokens=256
        )
        
        elyza_model = ELYZAModelInterface(config)
        success = await elyza_model.initialize_model()
        
        if success:
            prompt_generator = PromptGenerator()
            print("âœ… ELYZA model initialized successfully")
            return True
        else:
            print("âŒ ELYZA model initialization failed")
            return False
            
    except Exception as e:
        print(f"Error initializing ELYZA model: {e}")
        return False

@app.get("/")
async def serve_pwa():
    """Serve the PWA main page"""
    try:
        with open("frontend/index.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content, status_code=200)
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>Mac Status PWA</h1><p>Frontend files not found</p>",
            status_code=200
        )

@app.get("/fixed")
async def serve_fixed_pwa():
    """Serve the fixed PWA version"""
    try:
        with open("fixed_index.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content, status_code=200)
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>Fixed Mac Status PWA</h1><p>Fixed version not found</p>",
            status_code=200
        )

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

def get_system_info():
    """Get current system information"""
    try:
        # CPU usage
        cpu_percent = psutil.cpu_percent(interval=0.1)
        
        # Memory usage
        memory = psutil.virtual_memory()
        
        # Disk usage
        disk = psutil.disk_usage('/')
        
        # Top processes
        processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            try:
                info = proc.info
                if info['cpu_percent'] is not None and info['cpu_percent'] > 0:
                    processes.append(info)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # Sort by CPU usage and get top 5
        processes = sorted(processes, key=lambda x: x['cpu_percent'] or 0, reverse=True)[:5]
        
        return {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": round(cpu_percent, 1),
            "memory_percent": round(memory.percent, 1),
            "memory_used": memory.used,
            "memory_total": memory.total,
            "disk_percent": round((disk.used / disk.total) * 100, 1),
            "disk_used": disk.used,
            "disk_total": disk.total,
            "processes": processes
        }
    except Exception as e:
        print(f"Error getting system info: {e}")
        return {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": 0,
            "memory_percent": 0,
            "memory_used": 0,
            "memory_total": 1,
            "disk_percent": 0,
            "disk_used": 0,
            "disk_total": 1,
            "processes": [],
            "error": str(e)
        }

# Store connected clients
connected_clients = set()

async def broadcast_system_status():
    """Broadcast system status to all connected clients"""
    while True:
        if connected_clients:
            system_info = get_system_info()
            message = {
                "type": "system_status_update",
                "data": system_info,
                "timestamp": datetime.now().isoformat()
            }
            
            # Send to all connected clients
            disconnected_clients = set()
            for websocket in connected_clients:
                try:
                    await websocket.send_text(json.dumps(message))
                except:
                    disconnected_clients.add(websocket)
            
            # Remove disconnected clients
            connected_clients -= disconnected_clients
        
        await asyncio.sleep(2)  # Update every 2 seconds

# Start background task
@app.on_event("startup")
async def startup_event():
    asyncio.create_task(broadcast_system_status())
    # Initialize ELYZA model in background
    asyncio.create_task(initialize_elyza_model())

def generate_fallback_response(user_message: str, system_info: dict) -> str:
    """Generate fallback response when ELYZA model is not available"""
    
    user_message_lower = user_message.lower()
    
    # Get current system metrics
    cpu_usage = system_info.get("cpu_percent", 0)
    memory_percent = system_info.get("memory_percent", 0)
    memory_used_gb = system_info.get("memory_used", 0) / (1024**3)
    memory_total_gb = system_info.get("memory_total", 1) / (1024**3)
    disk_percent = system_info.get("disk_percent", 0)
    disk_used_gb = system_info.get("disk_used", 0) / (1024**3)
    disk_total_gb = system_info.get("disk_total", 1) / (1024**3)
    top_processes = system_info.get("processes", [])[:3]
    
    # Generate contextual responses based on keywords
    if "cpu" in user_message_lower or "ãƒ—ãƒ­ã‚»ãƒƒã‚µ" in user_message_lower or "ä½¿ç”¨ç‡" in user_message_lower:
        response_text = f"ğŸ–¥ï¸ ç¾åœ¨ã®CPUä½¿ç”¨ç‡ã¯ {cpu_usage}% ã§ã™ã€‚\n\n"
        if cpu_usage > 80:
            response_text += "âš ï¸ CPUä½¿ç”¨ç‡ãŒé«˜ã‚ã§ã™ã€‚é‡ã„å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        elif cpu_usage > 50:
            response_text += "ğŸ“Š CPUä½¿ç”¨ç‡ã¯ä¸­ç¨‹åº¦ã§ã™ã€‚é€šå¸¸ã®å‹•ä½œç¯„å›²å†…ã§ã™ã€‚"
        else:
            response_text += "âœ… CPUä½¿ç”¨ç‡ã¯ä½ãã€ã‚·ã‚¹ãƒ†ãƒ ã«ä½™è£•ãŒã‚ã‚Šã¾ã™ã€‚"
        
        if top_processes:
            response_text += f"\n\nä¸Šä½ãƒ—ãƒ­ã‚»ã‚¹:\n"
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                response_text += f"{i}. {proc['name']}: {cpu_val:.1f}%\n"
        
        return response_text
    
    elif "ãƒ¡ãƒ¢ãƒª" in user_message_lower or "memory" in user_message_lower or "ram" in user_message_lower:
        response_text = f"ğŸ’¾ ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³:\n\n"
        response_text += f"ä½¿ç”¨ç‡: {memory_percent}%\n"
        response_text += f"ä½¿ç”¨é‡: {memory_used_gb:.1f}GB / {memory_total_gb:.1f}GB\n"
        response_text += f"ç©ºãå®¹é‡: {(memory_total_gb - memory_used_gb):.1f}GB\n\n"
        
        if memory_percent > 85:
            response_text += "ğŸ”´ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‰ã˜ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
        elif memory_percent > 70:
            response_text += "ğŸŸ¡ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒã‚„ã‚„é«˜ã‚ã§ã™ã€‚"
        else:
            response_text += "ğŸŸ¢ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã¯æ­£å¸¸ç¯„å›²å†…ã§ã™ã€‚"
        
        return response_text
    
    elif "ãƒ‡ã‚£ã‚¹ã‚¯" in user_message_lower or "disk" in user_message_lower or "storage" in user_message_lower:
        response_text = f"ğŸ’¿ ç¾åœ¨ã®ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨çŠ¶æ³:\n\n"
        response_text += f"ä½¿ç”¨ç‡: {disk_percent}%\n"
        response_text += f"ä½¿ç”¨é‡: {disk_used_gb:.0f}GB / {disk_total_gb:.0f}GB\n"
        response_text += f"ç©ºãå®¹é‡: {(disk_total_gb - disk_used_gb):.0f}GB\n\n"
        
        if disk_percent > 90:
            response_text += "ğŸ”´ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ãŒå¿…è¦ã§ã™ã€‚"
        elif disk_percent > 80:
            response_text += "ğŸŸ¡ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãŒé«˜ã‚ã§ã™ã€‚ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
        else:
            response_text += "ğŸŸ¢ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã«ä½™è£•ãŒã‚ã‚Šã¾ã™ã€‚"
        
        return response_text
    
    elif "ã‚·ã‚¹ãƒ†ãƒ " in user_message_lower or "status" in user_message_lower or "å…¨ä½“" in user_message_lower or "çŠ¶æ³" in user_message_lower:
        response_text = f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®çŠ¶æ³\n\n"
        response_text += f"ğŸ–¥ï¸ CPU: {cpu_usage}%\n"
        response_text += f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}% ({memory_used_gb:.1f}GB/{memory_total_gb:.1f}GB)\n"
        response_text += f"ğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}% ({disk_used_gb:.0f}GB/{disk_total_gb:.0f}GB)\n\n"
        
        # Overall health assessment
        issues = []
        if cpu_usage > 80:
            issues.append("CPUä½¿ç”¨ç‡ãŒé«˜ã„")
        if memory_percent > 85:
            issues.append("ãƒ¡ãƒ¢ãƒªä¸è¶³")
        if disk_percent > 90:
            issues.append("ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³")
        
        if issues:
            response_text += f"âš ï¸ æ³¨æ„äº‹é …: {', '.join(issues)}"
        else:
            response_text += "âœ… ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™"
        
        return response_text
    
    elif "ã“ã‚“ã«ã¡ã¯" in user_message_lower or "hello" in user_message_lower:
        response_text = f"ğŸ‘‹ ã“ã‚“ã«ã¡ã¯ï¼Mac Status PWAã¸ã‚ˆã†ã“ãï¼\n\n"
        response_text += f"ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\n"
        response_text += f"ğŸ–¥ï¸ CPU: {cpu_usage}%\n"
        response_text += f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%\n"
        response_text += f"ğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%\n\n"
        response_text += f"ä½•ã‹ã”è³ªå•ãŒã‚ã‚Œã°ã€ãŠæ°—è»½ã«ãŠèããã ã•ã„ï¼"
        
        return response_text
    
    else:
        # Generate varied default responses
        import random
        
        responses = [
            f"ğŸ¤– ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ã‚’ãŠçŸ¥ã‚‰ã›ã—ã¾ã™ï¼š\nğŸ–¥ï¸ CPU: {cpu_usage}%\nğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%\nğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%",
            f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ä¸­ã§ã™ã€‚ç¾åœ¨ã®çŠ¶æ…‹ï¼š\nCPUä½¿ç”¨ç‡: {cpu_usage}%\nãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {memory_percent}%\nãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {disk_percent}%\n\nä»–ã«ä½•ã‹ãŠèãã—ãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            f"ğŸ” ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã—ãŸã€‚\nâ€¢ CPU: {cpu_usage}% {'(æ­£å¸¸)' if cpu_usage < 70 else '(é«˜ã‚)' if cpu_usage < 85 else '(æ³¨æ„)'}\nâ€¢ ãƒ¡ãƒ¢ãƒª: {memory_percent}% {'(æ­£å¸¸)' if memory_percent < 75 else '(é«˜ã‚)' if memory_percent < 90 else '(æ³¨æ„)'}\nâ€¢ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}% {'(æ­£å¸¸)' if disk_percent < 80 else '(é«˜ã‚)' if disk_percent < 95 else '(æ³¨æ„)'}",
            f"ğŸ’» Macã®çŠ¶æ…‹ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚\nCPU: {cpu_usage}%ã€ãƒ¡ãƒ¢ãƒª: {memory_percent}%ã€ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%\n\nè©³ã—ã„æƒ…å ±ãŒå¿…è¦ã§ã—ãŸã‚‰ã€ã€ŒCPUã®è©³ç´°ã€ã€Œãƒ¡ãƒ¢ãƒªã®è©³ç´°ã€ãªã©ã¨ãŠèããã ã•ã„ã€‚"
        ]
        
        return random.choice(responses)

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time communication"""
    await websocket.accept()
    connected_clients.add(websocket)
    print(f"WebSocket client connected. Total clients: {len(connected_clients)}")
    
    # Send initial system status
    try:
        system_info = get_system_info()
        initial_message = {
            "type": "system_status_response",
            "data": {
                "system_status": system_info
            },
            "timestamp": datetime.now().isoformat()
        }
        await websocket.send_text(json.dumps(initial_message))
    except Exception as e:
        print(f"Error sending initial status: {e}")
    
    try:
        while True:
            # Receive message from client
            data = await websocket.receive_text()
            print(f"Received: {data}")
            
            try:
                message = json.loads(data)
                message_type = message.get("type", "")
                
                if message_type == "ping":
                    # Respond to ping
                    response = {
                        "type": "pong",
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                elif message_type == "system_status_request":
                    # Get system information
                    system_info = get_system_info()
                    response = {
                        "type": "system_status_response",
                        "data": {
                            "system_status": system_info
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                elif message_type == "chat_message":
                    # Enhanced chat response
                    user_message = message.get("message", "")
                    system_info = get_system_info()
                    
                    response_text = None
                    
                    # Try to use ELYZA model first
                    if elyza_model and elyza_model.is_initialized and prompt_generator:
                        try:
                            # Generate prompt with system context
                            prompt = prompt_generator.generate_system_status_prompt(
                                user_query=user_message,
                                system_metrics={
                                    'cpu_percent': system_info.get("cpu_percent", 0),
                                    'memory_percent': system_info.get("memory_percent", 0),
                                    'memory_used_gb': system_info.get("memory_used", 0) / (1024**3),
                                    'memory_total_gb': system_info.get("memory_total", 1) / (1024**3),
                                    'disk_percent': system_info.get("disk_percent", 0),
                                    'disk_used_gb': system_info.get("disk_used", 0) / (1024**3),
                                    'disk_total_gb': system_info.get("disk_total", 1) / (1024**3),
                                    'top_processes': system_info.get("processes", [])[:3]
                                }
                            )
                            
                            # Get response from ELYZA model
                            model_response = await elyza_model.generate_response(prompt)
                            if model_response and model_response.content.strip():
                                response_text = model_response.content.strip()
                                print(f"âœ… ELYZA response generated: {len(response_text)} chars")
                            else:
                                print("âš ï¸ ELYZA returned empty response, using fallback")
                                
                        except Exception as e:
                            print(f"âŒ ELYZA model error: {e}")
                    
                    # If ELYZA model failed or not available, use fallback responses
                    if not response_text:
                        response_text = generate_fallback_response(user_message, system_info)
                        print(f"âœ… Fallback response generated: {len(response_text)} chars")
                    
                    response = {
                        "type": "chat_response",
                        "data": {
                            "message": response_text
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                else:
                    # Unknown message type
                    response = {
                        "type": "error",
                        "data": {
                            "message": f"Unknown message type: {message_type}"
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                    
            except json.JSONDecodeError:
                # Invalid JSON
                response = {
                    "type": "error",
                    "data": {
                        "message": "Invalid JSON format"
                    },
                    "timestamp": datetime.now().isoformat()
                }
                await websocket.send_text(json.dumps(response))
                
    except WebSocketDisconnect:
        connected_clients.discard(websocket)
        print(f"WebSocket client disconnected. Total clients: {len(connected_clients)}")

if __name__ == "__main__":
    print("ğŸš€ Starting Mac Status PWA Server (Fixed Version)")
    print("ELYZA model available:", ELYZA_AVAILABLE)
    uvicorn.run(app, host="0.0.0.0", port=8002)