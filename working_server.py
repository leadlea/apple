#!/usr/bin/env python3
"""
Working Mac Status PWA Server - Fixed Version
å‹•ä½œç¢ºèªæ¸ˆã¿ã®Mac Status PWAã‚µãƒ¼ãƒãƒ¼ï¼ˆä¿®æ­£ç‰ˆï¼‰
"""

import asyncio
import json
import psutil
from datetime import datetime
from pathlib import Path
import os
import sys

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
import uvicorn

# Add backend directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

# Import ELYZA model interface
try:
    from elyza_model import ELYZAModelInterface, ModelConfig
    from prompt_generator import PromptGenerator
    ELYZA_AVAILABLE = True
except ImportError as e:
    print(f"Warning: ELYZA model not available: {e}")
    ELYZA_AVAILABLE = False

# Create FastAPI app
app = FastAPI(title="Mac Status PWA - Working")

# Mount static files
app.mount("/static", StaticFiles(directory="frontend"), name="static")

# Initialize ELYZA model
elyza_model = None
prompt_generator = None

async def initialize_elyza_model():
    """Initialize ELYZA model if available"""
    global elyza_model, prompt_generator
    
    if not ELYZA_AVAILABLE:
        print("ELYZA model not available, using fallback responses")
        return False
    
    try:
        # Model configuration
        model_path = "models/elyza7b/ELYZA-japanese-Llama-2-7b-instruct.Q4_0.gguf"
        
        if not os.path.exists(model_path):
            print(f"Model file not found: {model_path}")
            print("Using fallback responses")
            return False
        
        config = ModelConfig(
            model_path=model_path,
            n_ctx=1024,  # Reduced for better performance
            n_gpu_layers=-1,  # Use all Metal layers on M1
            n_threads=4,
            temperature=0.7,
            max_tokens=256
        )
        
        elyza_model = ELYZAModelInterface(config)
        success = await elyza_model.initialize_model()
        
        if success:
            prompt_generator = PromptGenerator()
            print("âœ… ELYZA model initialized successfully")
            return True
        else:
            print("âŒ ELYZA model initialization failed")
            return False
            
    except Exception as e:
        print(f"Error initializing ELYZA model: {e}")
        return False

@app.get("/")
async def serve_pwa():
    """Serve the PWA main page"""
    try:
        with open("frontend/index.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content, status_code=200)
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>Mac Status PWA</h1><p>Frontend files not found</p>",
            status_code=200
        )

@app.get("/fixed")
async def serve_fixed_pwa():
    """Serve the fixed PWA version"""
    try:
        with open("fixed_index.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content, status_code=200)
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>Fixed Mac Status PWA</h1><p>Fixed version not found</p>",
            status_code=200
        )

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

def get_system_info():
    """Get current system information"""
    try:
        # CPU usage
        cpu_percent = psutil.cpu_percent(interval=0.1)
        
        # Memory usage
        memory = psutil.virtual_memory()
        
        # Disk usage
        disk = psutil.disk_usage('/')
        
        # Top processes
        processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            try:
                info = proc.info
                if info['cpu_percent'] is not None and info['cpu_percent'] > 0:
                    processes.append(info)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # Sort by CPU usage and get top 5
        processes = sorted(processes, key=lambda x: x['cpu_percent'] or 0, reverse=True)[:5]
        
        return {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": round(cpu_percent, 1),
            "memory_percent": round(memory.percent, 1),
            "memory_used": memory.used,
            "memory_total": memory.total,
            "disk_percent": round((disk.used / disk.total) * 100, 1),
            "disk_used": disk.used,
            "disk_total": disk.total,
            "processes": processes
        }
    except Exception as e:
        print(f"Error getting system info: {e}")
        return {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": 0,
            "memory_percent": 0,
            "memory_used": 0,
            "memory_total": 1,
            "disk_percent": 0,
            "disk_used": 0,
            "disk_total": 1,
            "processes": [],
            "error": str(e)
        }

# Store connected clients and conversation history
connected_clients = set()
conversation_history = {}  # websocket_id -> conversation data

class ConversationManager:
    def __init__(self):
        self.conversations = {}
    
    def get_conversation(self, client_id):
        if client_id not in self.conversations:
            self.conversations[client_id] = {
                'messages': [],
                'user_preferences': {
                    'politeness_level': 'polite',  # casual, polite, formal
                    'preferred_topics': [],
                    'question_patterns': {}
                },
                'session_start': datetime.now(),
                'last_interaction': datetime.now()
            }
        return self.conversations[client_id]
    
    def add_message(self, client_id, role, content):
        conv = self.get_conversation(client_id)
        conv['messages'].append({
            'role': role,
            'content': content,
            'timestamp': datetime.now()
        })
        conv['last_interaction'] = datetime.now()
        
        # Keep only last 20 messages to manage memory
        if len(conv['messages']) > 20:
            conv['messages'] = conv['messages'][-20:]
    
    def analyze_user_patterns(self, client_id, user_message):
        conv = self.get_conversation(client_id)
        
        # Track question patterns
        message_lower = user_message.lower()
        for keyword in ['cpu', 'ãƒ¡ãƒ¢ãƒª', 'ãƒ‡ã‚£ã‚¹ã‚¯', 'ã‚¢ãƒ—ãƒª', 'ãƒãƒƒãƒ†ãƒªãƒ¼']:
            if keyword in message_lower:
                if keyword not in conv['user_preferences']['question_patterns']:
                    conv['user_preferences']['question_patterns'][keyword] = 0
                conv['user_preferences']['question_patterns'][keyword] += 1
        
        # Adjust politeness based on user's language style
        if any(word in message_lower for word in ['ãã ã•ã„', 'ãŠé¡˜ã„', 'ã™ã¿ã¾ã›ã‚“']):
            conv['user_preferences']['politeness_level'] = 'formal'
        elif any(word in message_lower for word in ['ï¼Ÿ', 'ï¼', 'ã ã‚ˆ', 'ã˜ã‚ƒã‚“']):
            conv['user_preferences']['politeness_level'] = 'casual'
    
    def get_context_for_response(self, client_id):
        conv = self.get_conversation(client_id)
        recent_messages = conv['messages'][-5:]  # Last 5 messages
        return {
            'recent_messages': recent_messages,
            'preferences': conv['user_preferences'],
            'session_duration': (datetime.now() - conv['session_start']).total_seconds() / 60
        }

conversation_manager = ConversationManager()

async def broadcast_system_status():
    """Broadcast system status to all connected clients"""
    while True:
        if connected_clients:
            system_info = get_system_info()
            message = {
                "type": "system_status_update",
                "data": system_info,
                "timestamp": datetime.now().isoformat()
            }
            
            # Send to all connected clients
            disconnected_clients = set()
            for websocket in connected_clients:
                try:
                    await websocket.send_text(json.dumps(message))
                except:
                    disconnected_clients.add(websocket)
            
            # Remove disconnected clients
            connected_clients -= disconnected_clients
        
        await asyncio.sleep(2)  # Update every 2 seconds

# Start background task
@app.on_event("startup")
async def startup_event():
    asyncio.create_task(broadcast_system_status())
    # Initialize ELYZA model in background
    asyncio.create_task(initialize_elyza_model())

def generate_fallback_response(user_message: str, system_info: dict) -> str:
    """Generate fallback response when ELYZA model is not available"""
    
    user_message_lower = user_message.lower()
    
    # Get current system metrics
    cpu_usage = system_info.get("cpu_percent", 0)
    memory_percent = system_info.get("memory_percent", 0)
    memory_used_gb = system_info.get("memory_used", 0) / (1024**3)
    memory_total_gb = system_info.get("memory_total", 1) / (1024**3)
    disk_percent = system_info.get("disk_percent", 0)
    disk_used_gb = system_info.get("disk_used", 0) / (1024**3)
    disk_total_gb = system_info.get("disk_total", 1) / (1024**3)
    top_processes = system_info.get("processes", [])[:3]
    
    # Enhanced keyword detection with more variations
    def contains_keywords(text, keywords):
        return any(keyword in text for keyword in keywords)
    
    # Enhanced keyword detection for more specific responses
    
    # Battery related questions with varied responses
    if contains_keywords(user_message_lower, ["ãƒãƒƒãƒ†ãƒªãƒ¼", "battery", "é›»æ± ", "å……é›»"]):
        import random
        battery_responses = [
            "ğŸ”‹ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ãƒãƒƒãƒ†ãƒªãƒ¼æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—Macã®å ´åˆã€ãƒãƒƒãƒ†ãƒªãƒ¼æƒ…å ±ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚MacBookã‚’ãŠä½¿ã„ã®å ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒ†ãƒªãƒ¼ã§ç¢ºèªã§ãã¾ã™ã€‚",
            "ğŸ”‹ ãƒãƒƒãƒ†ãƒªãƒ¼æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™ã€‚\n\nMacBookã‚’ãŠä½¿ã„ã®å ´åˆã¯ã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒ†ãƒªãƒ¼ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã‹ã€ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒ†ãƒªãƒ¼ã§è©³ç´°ã‚’ç¢ºèªã§ãã¾ã™ã€‚",
            "ğŸ”‹ ç¾åœ¨ã€ãƒãƒƒãƒ†ãƒªãƒ¼ç›£è¦–æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nå……é›»çŠ¶æ³ã‚’ç¢ºèªã™ã‚‹ã«ã¯ï¼š\nâ€¢ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒ†ãƒªãƒ¼ã‚¢ã‚¤ã‚³ãƒ³\nâ€¢ ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒ†ãƒªãƒ¼\nâ€¢ ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ > ã‚¨ãƒãƒ«ã‚®ãƒ¼"
        ]
        return random.choice(battery_responses)
    
    # Running apps/processes
    elif contains_keywords(user_message_lower, ["ã‚¢ãƒ—ãƒª", "app", "ãƒ—ãƒ­ã‚»ã‚¹", "process", "å®Ÿè¡Œä¸­", "èµ·å‹•ä¸­", "å‹•ã„ã¦ã„ã‚‹"]):
        response_text = "ğŸ“± **ç¾åœ¨å®Ÿè¡Œä¸­ã®ä¸»è¦ãªãƒ—ãƒ­ã‚»ã‚¹:**\n\n"
        if top_processes:
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                mem_val = proc.get('memory_percent', 0) or 0
                response_text += f"**{i}. {proc['name']}**\n"
                response_text += f"   ğŸ–¥ï¸ CPU: {cpu_val:.1f}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {mem_val:.1f}%\n\n"
        else:
            response_text += "ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
        
        response_text += f"ğŸ“Š **ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ä½¿ç”¨çŠ¶æ³:**\n"
        response_text += f"ğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%"
        return response_text
    
    # Wi-Fi related questions with varied responses
    elif contains_keywords(user_message_lower, ["wifi", "wi-fi", "ãƒ¯ã‚¤ãƒ•ã‚¡ã‚¤", "ç„¡ç·š", "ãƒãƒƒãƒˆ", "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ", "æ¥ç¶š"]):
        import random
        wifi_responses = [
            f"ğŸ“¶ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨Wi-Fiæƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šçŠ¶æ³ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ç¢ºèªã§ãã¾ã™ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
            f"ğŸ“¶ Wi-Fiè©³ç´°æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯é–‹ç™ºäºˆå®šã§ã™ã€‚\n\næ¥ç¶šçŠ¶æ³ã‚’ç¢ºèªã™ã‚‹ã«ã¯ï¼š\nâ€¢ ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\nâ€¢ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã®Wi-Fiã‚¢ã‚¤ã‚³ãƒ³\nâ€¢ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
            f"ğŸ“¶ ç¾åœ¨ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è©³ç´°ç›£è¦–æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nWi-Fiæƒ…å ±ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®šã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%"
        ]
        return random.choice(wifi_responses)
    
    # CPU related questions
    elif contains_keywords(user_message_lower, ["cpu", "ãƒ—ãƒ­ã‚»ãƒƒã‚µ", "ä½¿ç”¨ç‡", "å‡¦ç†"]):
        response_text = f"ğŸ–¥ï¸ **ç¾åœ¨ã®CPUä½¿ç”¨ç‡ã¯ {cpu_usage}% ã§ã™ã€‚**\n\n"
        if cpu_usage > 80:
            response_text += "âš ï¸ CPUä½¿ç”¨ç‡ãŒé«˜ã‚ã§ã™ã€‚é‡ã„å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        elif cpu_usage > 50:
            response_text += "ğŸ“Š CPUä½¿ç”¨ç‡ã¯ä¸­ç¨‹åº¦ã§ã™ã€‚é€šå¸¸ã®å‹•ä½œç¯„å›²å†…ã§ã™ã€‚"
        else:
            response_text += "âœ… CPUä½¿ç”¨ç‡ã¯ä½ãã€ã‚·ã‚¹ãƒ†ãƒ ã«ä½™è£•ãŒã‚ã‚Šã¾ã™ã€‚"
        
        if top_processes:
            response_text += f"\n\n**ä¸Šä½ãƒ—ãƒ­ã‚»ã‚¹:**\n"
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                response_text += f"**{i}.** {proc['name']}: {cpu_val:.1f}%\n"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["ãƒ¡ãƒ¢ãƒª", "memory", "ram", "ä½¿ç”¨é‡"]):
        response_text = f"ğŸ’¾ **ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³:**\n\n"
        response_text += f"ğŸ“Š ä½¿ç”¨ç‡: **{memory_percent}%**\n"
        response_text += f"ğŸ“ˆ ä½¿ç”¨é‡: **{memory_used_gb:.1f}GB** / {memory_total_gb:.1f}GB\n"
        response_text += f"ğŸ’¿ ç©ºãå®¹é‡: **{(memory_total_gb - memory_used_gb):.1f}GB**\n\n"
        
        if memory_percent > 85:
            response_text += "ğŸ”´ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‰ã˜ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
        elif memory_percent > 70:
            response_text += "ğŸŸ¡ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒã‚„ã‚„é«˜ã‚ã§ã™ã€‚"
        else:
            response_text += "ğŸŸ¢ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã¯æ­£å¸¸ç¯„å›²å†…ã§ã™ã€‚"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["ãƒ‡ã‚£ã‚¹ã‚¯", "disk", "storage", "å®¹é‡"]):
        response_text = f"ğŸ’¿ **ç¾åœ¨ã®ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨çŠ¶æ³:**\n\n"
        response_text += f"ğŸ“Š ä½¿ç”¨ç‡: **{disk_percent}%**\n"
        response_text += f"ğŸ“ˆ ä½¿ç”¨é‡: **{disk_used_gb:.0f}GB** / {disk_total_gb:.0f}GB\n"
        response_text += f"ğŸ’¿ ç©ºãå®¹é‡: **{(disk_total_gb - disk_used_gb):.0f}GB**\n\n"
        
        if disk_percent > 90:
            response_text += "ğŸ”´ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ãŒå¿…è¦ã§ã™ã€‚"
        elif disk_percent > 80:
            response_text += "ğŸŸ¡ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãŒé«˜ã‚ã§ã™ã€‚ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
        else:
            response_text += "ğŸŸ¢ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã«ä½™è£•ãŒã‚ã‚Šã¾ã™ã€‚"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["ã‚·ã‚¹ãƒ†ãƒ ", "status", "å…¨ä½“", "çŠ¶æ³"]):
        response_text = f"ğŸ“Š **ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®çŠ¶æ³**\n\n"
        response_text += f"ğŸ–¥ï¸ CPU: **{cpu_usage}%**\n"
        response_text += f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: **{memory_percent}%** ({memory_used_gb:.1f}GB/{memory_total_gb:.1f}GB)\n"
        response_text += f"ğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: **{disk_percent}%** ({disk_used_gb:.0f}GB/{disk_total_gb:.0f}GB)\n\n"
        
        # Overall health assessment
        issues = []
        if cpu_usage > 80:
            issues.append("CPUä½¿ç”¨ç‡ãŒé«˜ã„")
        if memory_percent > 85:
            issues.append("ãƒ¡ãƒ¢ãƒªä¸è¶³")
        if disk_percent > 90:
            issues.append("ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³")
        
        if issues:
            response_text += f"âš ï¸ **æ³¨æ„äº‹é …:** {', '.join(issues)}"
        else:
            response_text += "âœ… **ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™**"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["ã“ã‚“ã«ã¡ã¯", "hello", "ã¯ã˜ã‚ã¾ã—ã¦", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯"]):
        response_text = f"ğŸ‘‹ ã“ã‚“ã«ã¡ã¯ï¼Mac Status PWAã¸ã‚ˆã†ã“ãï¼\n\n"
        response_text += f"ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\n"
        response_text += f"ğŸ–¥ï¸ CPU: {cpu_usage}%\n"
        response_text += f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%\n"
        response_text += f"ğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%\n\n"
        response_text += f"ä½•ã‹ã”è³ªå•ãŒã‚ã‚Œã°ã€ãŠæ°—è»½ã«ãŠèããã ã•ã„ï¼"
        
        return response_text
    
    else:
        # Generate contextual responses based on question patterns
        import random
        
        # Check if it's a question about specific functionality not yet implemented
        if any(word in user_message_lower for word in ["æ¸©åº¦", "temperature", "ç†±", "ãƒ•ã‚¡ãƒ³", "fan"]):
            import random
            temp_responses = [
                f"ğŸŒ¡ï¸ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨æ¸©åº¦æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ã‚¢ãƒ—ãƒªï¼ˆTG Proã€Macs Fan Controlç­‰ï¼‰ã§æ¸©åº¦ç›£è¦–ãŒå¯èƒ½ã§ã™ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
                f"ğŸŒ¡ï¸ æ¸©åº¦ãƒ»ãƒ•ã‚¡ãƒ³ç›£è¦–æ©Ÿèƒ½ã¯ä»Šå¾Œã®å®Ÿè£…äºˆå®šã§ã™ã€‚\n\nç¾åœ¨åˆ©ç”¨å¯èƒ½ãªæ¸©åº¦ç›£è¦–æ–¹æ³•ï¼š\nâ€¢ TG Proï¼ˆApp Storeï¼‰\nâ€¢ Macs Fan Controlï¼ˆç„¡æ–™ï¼‰\nâ€¢ iStat Menusï¼ˆæœ‰æ–™ï¼‰\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
                f"ğŸŒ¡ï¸ ã‚·ã‚¹ãƒ†ãƒ æ¸©åº¦ã®ç›£è¦–æ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚\n\nä»£æ›¿æ‰‹æ®µã¨ã—ã¦ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ã§CPUä½¿ç”¨ç‡ã‹ã‚‰è² è·çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%"
            ]
            return random.choice(temp_responses)
        
        elif any(word in user_message_lower for word in ["ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "network", "é€šä¿¡", "é€Ÿåº¦", "å¸¯åŸŸ"]):
            import random
            network_responses = [
                f"ğŸŒ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è©³ç´°æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½¿ç”¨çŠ¶æ³ã¯ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¿ãƒ–ã§ç¢ºèªã§ãã¾ã™ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
                f"ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦ãƒ»ä½¿ç”¨é‡ç›£è¦–æ©Ÿèƒ½ã¯é–‹ç™ºäºˆå®šã§ã™ã€‚\n\nç¾åœ¨ã®ç¢ºèªæ–¹æ³•ï¼š\nâ€¢ ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\nâ€¢ ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\nâ€¢ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%"
            ]
            return random.choice(network_responses)
        
        # Generate varied helpful responses
        responses = [
            f"ğŸ¤– ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ã‚’ãŠçŸ¥ã‚‰ã›ã—ã¾ã™ï¼š\n\nğŸ–¥ï¸ CPU: {cpu_usage}%\nğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%\nğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%\n\nã€ŒCPUã®è©³ç´°ã€ã€Œãƒ¡ãƒ¢ãƒªã®çŠ¶æ³ã€ã€Œå®Ÿè¡Œä¸­ã®ã‚¢ãƒ—ãƒªã€ãªã©ã¨ãŠèããã ã•ã„ã€‚",
            f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ä¸­ã§ã™ã€‚ç¾åœ¨ã®çŠ¶æ…‹ï¼š\n\nCPUä½¿ç”¨ç‡: {cpu_usage}%\nãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {memory_percent}%\nãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {disk_percent}%\n\nä»–ã«ä½•ã‹ãŠèãã—ãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            f"ğŸ” ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã—ãŸã€‚\n\nâ€¢ CPU: {cpu_usage}% {'(æ­£å¸¸)' if cpu_usage < 70 else '(é«˜ã‚)' if cpu_usage < 85 else '(æ³¨æ„)'}\nâ€¢ ãƒ¡ãƒ¢ãƒª: {memory_percent}% {'(æ­£å¸¸)' if memory_percent < 75 else '(é«˜ã‚)' if memory_percent < 90 else '(æ³¨æ„)'}\nâ€¢ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}% {'(æ­£å¸¸)' if disk_percent < 80 else '(é«˜ã‚)' if disk_percent < 95 else '(æ³¨æ„)'}\n\nè©³ã—ã„æƒ…å ±ãŒå¿…è¦ã§ã—ãŸã‚‰ã€å…·ä½“çš„ã«ãŠèããã ã•ã„ã€‚",
            f"ğŸ’» Macã®çŠ¶æ…‹ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚\n\nCPU: {cpu_usage}%ã€ãƒ¡ãƒ¢ãƒª: {memory_percent}%ã€ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%\n\nã€Œãƒãƒƒãƒ†ãƒªãƒ¼ã¯ï¼Ÿã€ã€ŒWi-Fiã¯ï¼Ÿã€ã€Œå®Ÿè¡Œä¸­ã®ã‚¢ãƒ—ãƒªã¯ï¼Ÿã€ãªã©ã¨ãŠèããã ã•ã„ã€‚"
        ]
        
        return random.choice(responses)

def get_time_based_greeting():
    """æ™‚é–“å¸¯ã«å¿œã˜ãŸæŒ¨æ‹¶ã‚’å–å¾—"""
    current_hour = datetime.now().hour
    
    if 5 <= current_hour < 10:
        return "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™"
    elif 10 <= current_hour < 18:
        return "ã“ã‚“ã«ã¡ã¯"
    elif 18 <= current_hour < 22:
        return "ã“ã‚“ã°ã‚“ã¯"
    else:
        return "ãŠç–²ã‚Œã•ã¾ã§ã™"

def generate_personalized_response(user_message: str, system_info: dict, context: dict = None) -> str:
    """Generate personalized response based on user context and system info"""
    
    user_message_lower = user_message.lower()
    
    # Get current system metrics
    cpu_usage = system_info.get("cpu_percent", 0)
    memory_percent = system_info.get("memory_percent", 0)
    memory_used_gb = system_info.get("memory_used", 0) / (1024**3)
    memory_total_gb = system_info.get("memory_total", 1) / (1024**3)
    disk_percent = system_info.get("disk_percent", 0)
    disk_used_gb = system_info.get("disk_used", 0) / (1024**3)
    disk_total_gb = system_info.get("disk_total", 1) / (1024**3)
    top_processes = system_info.get("processes", [])[:3]
    
    # Get user context and preferences
    politeness_level = 'polite'
    recent_questions = []
    session_duration = 0
    
    if context:
        politeness_level = context.get('preferences', {}).get('politeness_level', 'polite')
        recent_questions = [msg['content'] for msg in context.get('recent_messages', []) if msg['role'] == 'user']
        session_duration = context.get('session_duration', 0)
    
    # Enhanced keyword detection with more variations
    def contains_keywords(text, keywords):
        return any(keyword in text for keyword in keywords)
    
    # Adjust response style based on politeness level
    def format_response(base_response, politeness_level):
        if politeness_level == 'casual':
            return base_response.replace('ã§ã™ã€‚', 'ã ã‚ˆã€‚').replace('ã¾ã™ã€‚', 'ã‚‹ã‚ˆã€‚').replace('ã”ã–ã„ã¾ã™', 'ã‚ã‚Šã¾ã™')
        elif politeness_level == 'formal':
            return base_response.replace('ã ã‚ˆ', 'ã§ã™').replace('ã‚‹ã‚ˆ', 'ã¾ã™')
        return base_response
    
    # Enhanced keyword detection for more specific responses
    
    # Battery related questions with varied responses
    if contains_keywords(user_message_lower, ["ãƒãƒƒãƒ†ãƒªãƒ¼", "battery", "é›»æ± ", "å……é›»"]):
        import random
        battery_responses = [
            "ğŸ”‹ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ãƒãƒƒãƒ†ãƒªãƒ¼æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—Macã®å ´åˆã€ãƒãƒƒãƒ†ãƒªãƒ¼æƒ…å ±ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚MacBookã‚’ãŠä½¿ã„ã®å ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒ†ãƒªãƒ¼ã§ç¢ºèªã§ãã¾ã™ã€‚",
            "ğŸ”‹ ãƒãƒƒãƒ†ãƒªãƒ¼æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™ã€‚\n\nMacBookã‚’ãŠä½¿ã„ã®å ´åˆã¯ã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒ†ãƒªãƒ¼ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã‹ã€ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒ†ãƒªãƒ¼ã§è©³ç´°ã‚’ç¢ºèªã§ãã¾ã™ã€‚",
            "ğŸ”‹ ç¾åœ¨ã€ãƒãƒƒãƒ†ãƒªãƒ¼ç›£è¦–æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nå……é›»çŠ¶æ³ã‚’ç¢ºèªã™ã‚‹ã«ã¯ï¼š\nâ€¢ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒ†ãƒªãƒ¼ã‚¢ã‚¤ã‚³ãƒ³\nâ€¢ ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒ†ãƒªãƒ¼\nâ€¢ ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ > ã‚¨ãƒãƒ«ã‚®ãƒ¼"
        ]
        return random.choice(battery_responses)
    
    # Running apps/processes
    elif contains_keywords(user_message_lower, ["ã‚¢ãƒ—ãƒª", "app", "ãƒ—ãƒ­ã‚»ã‚¹", "process", "å®Ÿè¡Œä¸­", "èµ·å‹•ä¸­", "å‹•ã„ã¦ã„ã‚‹"]):
        response_text = "ğŸ“± **ç¾åœ¨å®Ÿè¡Œä¸­ã®ä¸»è¦ãªãƒ—ãƒ­ã‚»ã‚¹:**\n\n"
        if top_processes:
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                mem_val = proc.get('memory_percent', 0) or 0
                response_text += f"**{i}. {proc['name']}**\n"
                response_text += f"   ğŸ–¥ï¸ CPU: {cpu_val:.1f}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {mem_val:.1f}%\n\n"
        else:
            response_text += "ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
        
        response_text += f"ğŸ“Š **ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ä½¿ç”¨çŠ¶æ³:**\n"
        response_text += f"ğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%"
        return response_text
    
    # Wi-Fi related questions with varied responses
    elif contains_keywords(user_message_lower, ["wifi", "wi-fi", "ãƒ¯ã‚¤ãƒ•ã‚¡ã‚¤", "ç„¡ç·š", "ãƒãƒƒãƒˆ", "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ", "æ¥ç¶š"]):
        import random
        wifi_responses = [
            f"ğŸ“¶ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨Wi-Fiæƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šçŠ¶æ³ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ç¢ºèªã§ãã¾ã™ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
            f"ğŸ“¶ Wi-Fiè©³ç´°æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯é–‹ç™ºäºˆå®šã§ã™ã€‚\n\næ¥ç¶šçŠ¶æ³ã‚’ç¢ºèªã™ã‚‹ã«ã¯ï¼š\nâ€¢ ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\nâ€¢ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã®Wi-Fiã‚¢ã‚¤ã‚³ãƒ³\nâ€¢ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
            f"ğŸ“¶ ç¾åœ¨ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è©³ç´°ç›£è¦–æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nWi-Fiæƒ…å ±ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®šã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%"
        ]
        return random.choice(wifi_responses)
    
    # CPU related questions
    elif contains_keywords(user_message_lower, ["cpu", "ãƒ—ãƒ­ã‚»ãƒƒã‚µ", "ä½¿ç”¨ç‡", "å‡¦ç†"]):
        response_text = f"ğŸ–¥ï¸ **ç¾åœ¨ã®CPUä½¿ç”¨ç‡ã¯ {cpu_usage}% ã§ã™ã€‚**\n\n"
        if cpu_usage > 80:
            response_text += "âš ï¸ CPUä½¿ç”¨ç‡ãŒé«˜ã‚ã§ã™ã€‚é‡ã„å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        elif cpu_usage > 50:
            response_text += "ğŸ“Š CPUä½¿ç”¨ç‡ã¯ä¸­ç¨‹åº¦ã§ã™ã€‚é€šå¸¸ã®å‹•ä½œç¯„å›²å†…ã§ã™ã€‚"
        else:
            response_text += "âœ… CPUä½¿ç”¨ç‡ã¯ä½ãã€ã‚·ã‚¹ãƒ†ãƒ ã«ä½™è£•ãŒã‚ã‚Šã¾ã™ã€‚"
        
        if top_processes:
            response_text += f"\n\n**ä¸Šä½ãƒ—ãƒ­ã‚»ã‚¹:**\n"
            for i, proc in enumerate(top_processes, 1):
                cpu_val = proc.get('cpu_percent', 0) or 0
                response_text += f"**{i}.** {proc['name']}: {cpu_val:.1f}%\n"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["ãƒ¡ãƒ¢ãƒª", "memory", "ram", "ä½¿ç”¨é‡"]):
        response_text = f"ğŸ’¾ **ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³:**\n\n"
        response_text += f"ğŸ“Š ä½¿ç”¨ç‡: **{memory_percent}%**\n"
        response_text += f"ğŸ“ˆ ä½¿ç”¨é‡: **{memory_used_gb:.1f}GB** / {memory_total_gb:.1f}GB\n"
        response_text += f"ğŸ’¿ ç©ºãå®¹é‡: **{(memory_total_gb - memory_used_gb):.1f}GB**\n\n"
        
        if memory_percent > 85:
            response_text += "ğŸ”´ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‰ã˜ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
        elif memory_percent > 70:
            response_text += "ğŸŸ¡ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒã‚„ã‚„é«˜ã‚ã§ã™ã€‚"
        else:
            response_text += "ğŸŸ¢ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã¯æ­£å¸¸ç¯„å›²å†…ã§ã™ã€‚"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["ãƒ‡ã‚£ã‚¹ã‚¯", "disk", "storage", "å®¹é‡"]):
        response_text = f"ğŸ’¿ **ç¾åœ¨ã®ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨çŠ¶æ³:**\n\n"
        response_text += f"ğŸ“Š ä½¿ç”¨ç‡: **{disk_percent}%**\n"
        response_text += f"ğŸ“ˆ ä½¿ç”¨é‡: **{disk_used_gb:.0f}GB** / {disk_total_gb:.0f}GB\n"
        response_text += f"ğŸ’¿ ç©ºãå®¹é‡: **{(disk_total_gb - disk_used_gb):.0f}GB**\n\n"
        
        if disk_percent > 90:
            response_text += "ğŸ”´ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ãŒå¿…è¦ã§ã™ã€‚"
        elif disk_percent > 80:
            response_text += "ğŸŸ¡ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãŒé«˜ã‚ã§ã™ã€‚ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
        else:
            response_text += "ğŸŸ¢ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã«ä½™è£•ãŒã‚ã‚Šã¾ã™ã€‚"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["ã‚·ã‚¹ãƒ†ãƒ ", "status", "å…¨ä½“", "çŠ¶æ³"]):
        response_text = f"ğŸ“Š **ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®çŠ¶æ³**\n\n"
        response_text += f"ğŸ–¥ï¸ CPU: **{cpu_usage}%**\n"
        response_text += f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: **{memory_percent}%** ({memory_used_gb:.1f}GB/{memory_total_gb:.1f}GB)\n"
        response_text += f"ğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: **{disk_percent}%** ({disk_used_gb:.0f}GB/{disk_total_gb:.0f}GB)\n\n"
        
        # Overall health assessment
        issues = []
        if cpu_usage > 80:
            issues.append("CPUä½¿ç”¨ç‡ãŒé«˜ã„")
        if memory_percent > 85:
            issues.append("ãƒ¡ãƒ¢ãƒªä¸è¶³")
        if disk_percent > 90:
            issues.append("ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³")
        
        if issues:
            response_text += f"âš ï¸ **æ³¨æ„äº‹é …:** {', '.join(issues)}"
        else:
            response_text += "âœ… **ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™**"
        
        return response_text
    
    elif contains_keywords(user_message_lower, ["ã“ã‚“ã«ã¡ã¯", "hello", "ã¯ã˜ã‚ã¾ã—ã¦", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯"]):
        response_text = f"ğŸ‘‹ ã“ã‚“ã«ã¡ã¯ï¼Mac Status PWAã¸ã‚ˆã†ã“ãï¼\n\n"
        response_text += f"ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\n"
        response_text += f"ğŸ–¥ï¸ CPU: {cpu_usage}%\n"
        response_text += f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%\n"
        response_text += f"ğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%\n\n"
        response_text += f"ä½•ã‹ã”è³ªå•ãŒã‚ã‚Œã°ã€ãŠæ°—è»½ã«ãŠèããã ã•ã„ï¼"
        
        return response_text
    
    else:
        # Generate contextual responses based on question patterns
        import random
        
        # Check if it's a question about specific functionality not yet implemented
        if any(word in user_message_lower for word in ["æ¸©åº¦", "temperature", "ç†±", "ãƒ•ã‚¡ãƒ³", "fan"]):
            import random
            temp_responses = [
                f"ğŸŒ¡ï¸ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨æ¸©åº¦æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ã‚¢ãƒ—ãƒªï¼ˆTG Proã€Macs Fan Controlç­‰ï¼‰ã§æ¸©åº¦ç›£è¦–ãŒå¯èƒ½ã§ã™ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
                f"ğŸŒ¡ï¸ æ¸©åº¦ãƒ»ãƒ•ã‚¡ãƒ³ç›£è¦–æ©Ÿèƒ½ã¯ä»Šå¾Œã®å®Ÿè£…äºˆå®šã§ã™ã€‚\n\nç¾åœ¨åˆ©ç”¨å¯èƒ½ãªæ¸©åº¦ç›£è¦–æ–¹æ³•ï¼š\nâ€¢ TG Proï¼ˆApp Storeï¼‰\nâ€¢ Macs Fan Controlï¼ˆç„¡æ–™ï¼‰\nâ€¢ iStat Menusï¼ˆæœ‰æ–™ï¼‰\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
                f"ğŸŒ¡ï¸ ã‚·ã‚¹ãƒ†ãƒ æ¸©åº¦ã®ç›£è¦–æ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚\n\nä»£æ›¿æ‰‹æ®µã¨ã—ã¦ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ã§CPUä½¿ç”¨ç‡ã‹ã‚‰è² è·çŠ¶æ³ã‚’ç¢ºèªã§ãã¾ã™ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%"
            ]
            return random.choice(temp_responses)
        
        elif any(word in user_message_lower for word in ["ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "network", "é€šä¿¡", "é€Ÿåº¦", "å¸¯åŸŸ"]):
            import random
            network_responses = [
                f"ğŸŒ ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è©³ç´°æƒ…å ±ã®å–å¾—æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½¿ç”¨çŠ¶æ³ã¯ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¿ãƒ–ã§ç¢ºèªã§ãã¾ã™ã€‚\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%",
                f"ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦ãƒ»ä½¿ç”¨é‡ç›£è¦–æ©Ÿèƒ½ã¯é–‹ç™ºäºˆå®šã§ã™ã€‚\n\nç¾åœ¨ã®ç¢ºèªæ–¹æ³•ï¼š\nâ€¢ ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\nâ€¢ ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\nâ€¢ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n\nç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:\nğŸ–¥ï¸ CPU: {cpu_usage}% | ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%"
            ]
            return random.choice(network_responses)
        
        # Generate varied helpful responses
        responses = [
            f"ğŸ¤– ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ã‚’ãŠçŸ¥ã‚‰ã›ã—ã¾ã™ï¼š\n\nğŸ–¥ï¸ CPU: {cpu_usage}%\nğŸ’¾ ãƒ¡ãƒ¢ãƒª: {memory_percent}%\nğŸ’¿ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%\n\nã€ŒCPUã®è©³ç´°ã€ã€Œãƒ¡ãƒ¢ãƒªã®çŠ¶æ³ã€ã€Œå®Ÿè¡Œä¸­ã®ã‚¢ãƒ—ãƒªã€ãªã©ã¨ãŠèããã ã•ã„ã€‚",
            f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ä¸­ã§ã™ã€‚ç¾åœ¨ã®çŠ¶æ…‹ï¼š\n\nCPUä½¿ç”¨ç‡: {cpu_usage}%\nãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {memory_percent}%\nãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {disk_percent}%\n\nä»–ã«ä½•ã‹ãŠèãã—ãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            f"ğŸ” ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã—ãŸã€‚\n\nâ€¢ CPU: {cpu_usage}% {'(æ­£å¸¸)' if cpu_usage < 70 else '(é«˜ã‚)' if cpu_usage < 85 else '(æ³¨æ„)'}\nâ€¢ ãƒ¡ãƒ¢ãƒª: {memory_percent}% {'(æ­£å¸¸)' if memory_percent < 75 else '(é«˜ã‚)' if memory_percent < 90 else '(æ³¨æ„)'}\nâ€¢ ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}% {'(æ­£å¸¸)' if disk_percent < 80 else '(é«˜ã‚)' if disk_percent < 95 else '(æ³¨æ„)'}\n\nè©³ã—ã„æƒ…å ±ãŒå¿…è¦ã§ã—ãŸã‚‰ã€å…·ä½“çš„ã«ãŠèããã ã•ã„ã€‚",
            f"ğŸ’» Macã®çŠ¶æ…‹ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚\n\nCPU: {cpu_usage}%ã€ãƒ¡ãƒ¢ãƒª: {memory_percent}%ã€ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent}%\n\nã€Œãƒãƒƒãƒ†ãƒªãƒ¼ã¯ï¼Ÿã€ã€ŒWi-Fiã¯ï¼Ÿã€ã€Œå®Ÿè¡Œä¸­ã®ã‚¢ãƒ—ãƒªã¯ï¼Ÿã€ãªã©ã¨ãŠèããã ã•ã„ã€‚"
        ]
        
        return random.choice(responses)

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time communication"""
    await websocket.accept()
    connected_clients.add(websocket)
    print(f"WebSocket client connected. Total clients: {len(connected_clients)}")
    
    # Send initial system status
    try:
        system_info = get_system_info()
        initial_message = {
            "type": "system_status_response",
            "data": {
                "system_status": system_info
            },
            "timestamp": datetime.now().isoformat()
        }
        await websocket.send_text(json.dumps(initial_message))
    except Exception as e:
        print(f"Error sending initial status: {e}")
    
    try:
        while True:
            # Receive message from client
            data = await websocket.receive_text()
            print(f"Received: {data}")
            
            try:
                message = json.loads(data)
                message_type = message.get("type", "")
                
                if message_type == "ping":
                    # Respond to ping
                    response = {
                        "type": "pong",
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                elif message_type == "system_status_request":
                    # Get system information
                    system_info = get_system_info()
                    response = {
                        "type": "system_status_response",
                        "data": {
                            "system_status": system_info
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                elif message_type == "chat_message":
                    # Enhanced chat response
                    # Handle both direct message and nested data.message formats
                    user_message = ""
                    if "data" in message and isinstance(message["data"], dict):
                        user_message = message["data"].get("message", "")
                    else:
                        user_message = message.get("message", "")
                    
                    print(f"ğŸ” Processing chat message: '{user_message}'")
                    system_info = get_system_info()
                    
                    response_text = None
                    
                    # Try to use ELYZA model first
                    if elyza_model and elyza_model.is_initialized and prompt_generator:
                        try:
                            # Generate prompt with system context
                            prompt = prompt_generator.generate_system_status_prompt(
                                user_query=user_message,
                                system_metrics={
                                    'cpu_percent': system_info.get("cpu_percent", 0),
                                    'memory_percent': system_info.get("memory_percent", 0),
                                    'memory_used_gb': system_info.get("memory_used", 0) / (1024**3),
                                    'memory_total_gb': system_info.get("memory_total", 1) / (1024**3),
                                    'disk_percent': system_info.get("disk_percent", 0),
                                    'disk_used_gb': system_info.get("disk_used", 0) / (1024**3),
                                    'disk_total_gb': system_info.get("disk_total", 1) / (1024**3),
                                    'top_processes': system_info.get("processes", [])[:3]
                                }
                            )
                            
                            # Get response from ELYZA model
                            model_response = await elyza_model.generate_response(prompt)
                            if model_response and model_response.content.strip():
                                response_text = model_response.content.strip()
                                print(f"âœ… ELYZA response generated: {len(response_text)} chars")
                            else:
                                print("âš ï¸ ELYZA returned empty response, using fallback")
                                
                        except Exception as e:
                            print(f"âŒ ELYZA model error: {e}")
                    
                    # If ELYZA model failed or not available, use fallback responses
                    if not response_text:
                        response_text = generate_fallback_response(user_message, system_info)
                        print(f"âœ… Fallback response generated for '{user_message}': {len(response_text)} chars")
                        print(f"ğŸ“ Response preview: {response_text[:50]}...")
                    
                    response = {
                        "type": "chat_response",
                        "data": {
                            "message": response_text
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                
                else:
                    # Unknown message type
                    response = {
                        "type": "error",
                        "data": {
                            "message": f"Unknown message type: {message_type}"
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send_text(json.dumps(response))
                    
            except json.JSONDecodeError:
                # Invalid JSON
                response = {
                    "type": "error",
                    "data": {
                        "message": "Invalid JSON format"
                    },
                    "timestamp": datetime.now().isoformat()
                }
                await websocket.send_text(json.dumps(response))
                
    except WebSocketDisconnect:
        connected_clients.discard(websocket)
        print(f"WebSocket client disconnected. Total clients: {len(connected_clients)}")

if __name__ == "__main__":
    print("ğŸš€ Starting Mac Status PWA Server (Fixed Version)")
    print("ELYZA model available:", ELYZA_AVAILABLE)
    uvicorn.run(app, host="0.0.0.0", port=8002)