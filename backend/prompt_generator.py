"""
Japanese Prompt Generation System for Mac Status PWA
Converts system information and conversation context into Japanese prompts for ELYZA model
"""
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
from enum import Enum
import re


class PromptStyle(Enum):
    """Different prompt styles for various interaction types"""
    CASUAL = "casual"           # ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªä¼šè©±
    TECHNICAL = "technical"     # æŠ€è¡“çš„ãªè©³ç´°
    FRIENDLY = "friendly"       # ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå¯¾è©±
    PROFESSIONAL = "professional"  # ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«


class SystemMetricType(Enum):
    """Types of system metrics for focused responses"""
    CPU = "cpu"
    MEMORY = "memory"
    DISK = "disk"
    PROCESSES = "processes"
    NETWORK = "network"
    BATTERY = "battery"
    WIFI = "wifi"
    APPS = "apps"
    DISK_DETAILS = "disk_details"
    DEV_TOOLS = "dev_tools"
    THERMAL = "thermal"
    GENERAL = "general"


@dataclass
class ConversationContext:
    """Context information for conversation continuity"""
    user_name: Optional[str] = None
    preferred_style: PromptStyle = PromptStyle.FRIENDLY
    recent_topics: List[str] = None
    user_expertise_level: str = "beginner"  # beginner, intermediate, advanced
    conversation_history: List[Dict[str, str]] = None
    
    def __post_init__(self):
        if self.recent_topics is None:
            self.recent_topics = []
        if self.conversation_history is None:
            self.conversation_history = []


@dataclass
class PromptTemplate:
    """Template for generating prompts"""
    system_role: str
    context_format: str
    user_query_format: str
    response_guidelines: List[str]
    style_modifiers: Dict[str, str]


class PromptGenerator:
    """
    Generates Japanese prompts for ELYZA model based on system data and conversation context
    """
    
    def __init__(self):
        """Initialize the prompt generator with templates and formatting rules"""
        self.templates = self._initialize_templates()
        self.system_formatters = self._initialize_system_formatters()
        self.conversation_patterns = self._initialize_conversation_patterns()
        
    def _initialize_templates(self) -> Dict[PromptStyle, PromptTemplate]:
        """Initialize prompt templates for different styles"""
        return {
            PromptStyle.CASUAL: PromptTemplate(
                system_role="ã‚ãªãŸã¯Macã®çŠ¶æ…‹ã‚’ç›£è¦–ã™ã‚‹è¦ªã—ã¿ã‚„ã™ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨æ°—è»½ã«ä¼šè©±ã—ãªãŒã‚‰ã€ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¾ã™ã€‚",
                context_format="ç¾åœ¨ã®Macã®çŠ¶æ…‹:\n{system_info}\n",
                user_query_format="ãƒ¦ãƒ¼ã‚¶ãƒ¼: {query}\n",
                response_guidelines=[
                    "è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§è©±ã™",
                    "å°‚é–€ç”¨èªã¯åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹", 
                    "å¿…è¦ã«å¿œã˜ã¦çµµæ–‡å­—ã‚’ä½¿ç”¨ã™ã‚‹",
                    "ç°¡æ½”ã§ç†è§£ã—ã‚„ã™ã„å›ç­”ã‚’ã™ã‚‹"
                ],
                style_modifiers={
                    "greeting": "ã“ã‚“ã«ã¡ã¯ï¼",
                    "concern": "ã¡ã‚‡ã£ã¨æ°—ã«ãªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã­",
                    "good_news": "è‰¯ã„æ„Ÿã˜ã§ã™ã­ï¼",
                    "suggestion": "ã“ã‚“ãªã“ã¨ã‚’è©¦ã—ã¦ã¿ã¦ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹"
                }
            ),
            
            PromptStyle.TECHNICAL: PromptTemplate(
                system_role="ã‚ãªãŸã¯Macã‚·ã‚¹ãƒ†ãƒ ã®æŠ€è¡“çš„ãªè©³ç´°ã«ç²¾é€šã—ãŸå°‚é–€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ­£ç¢ºã§è©³ç´°ãªæŠ€è¡“æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚",
                context_format="ã‚·ã‚¹ãƒ†ãƒ è©³ç´°æƒ…å ±:\n{system_info}\n",
                user_query_format="ã‚¯ã‚¨ãƒª: {query}\n",
                response_guidelines=[
                    "æŠ€è¡“çš„ã«æ­£ç¢ºãªæƒ…å ±ã‚’æä¾›ã™ã‚‹",
                    "å…·ä½“çš„ãªæ•°å€¤ã‚„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å«ã‚ã‚‹",
                    "å°‚é–€ç”¨èªã‚’é©åˆ‡ã«ä½¿ç”¨ã™ã‚‹",
                    "è©³ç´°ãªåˆ†æã¨æ¨å¥¨äº‹é …ã‚’æä¾›ã™ã‚‹"
                ],
                style_modifiers={
                    "analysis": "ã‚·ã‚¹ãƒ†ãƒ åˆ†æçµæœ:",
                    "metrics": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹:",
                    "recommendation": "æŠ€è¡“çš„æ¨å¥¨äº‹é …:",
                    "warning": "æ³¨æ„ãŒå¿…è¦ãªé …ç›®:"
                }
            ),
            
            PromptStyle.FRIENDLY: PromptTemplate(
                system_role="ã‚ãªãŸã¯Macãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é ¼ã‚Œã‚‹å‹äººã®ã‚ˆã†ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ¸©ã‹ãè¦ªåˆ‡ã«ã€ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚",
                context_format="ã‚ãªãŸã®Macã®ä»Šã®æ§˜å­:\n{system_info}\n",
                user_query_format="è³ªå•: {query}\n",
                response_guidelines=[
                    "æ¸©ã‹ãè¦ªåˆ‡ãªå£èª¿ã§å¯¾å¿œã™ã‚‹",
                    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿ƒé…äº‹ã«å…±æ„Ÿã™ã‚‹",
                    "åˆ†ã‹ã‚Šã‚„ã™ã„ä¾‹ãˆã‚’ä½¿ç”¨ã™ã‚‹",
                    "å®‰å¿ƒæ„Ÿã‚’ä¸ãˆã‚‹å›ç­”ã‚’ã™ã‚‹"
                ],
                style_modifiers={
                    "reassurance": "ã”å®‰å¿ƒãã ã•ã„",
                    "explanation": "ç°¡å˜ã«èª¬æ˜ã™ã‚‹ã¨",
                    "help": "ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™",
                    "status": "ç¾åœ¨ã®çŠ¶æ³ã¯"
                }
            ),
            
            PromptStyle.PROFESSIONAL: PromptTemplate(
                system_role="ã‚ãªãŸã¯Macã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã®å°‚é–€å®¶ã¨ã—ã¦ã€ãƒ“ã‚¸ãƒã‚¹ç’°å¢ƒã§ã®ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚",
                context_format="ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ:\n{system_info}\n",
                user_query_format="ãŠå•ã„åˆã‚ã›: {query}\n",
                response_guidelines=[
                    "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ä¸å¯§ãªè¨€è‘‰é£ã„",
                    "ãƒ“ã‚¸ãƒã‚¹å½±éŸ¿ã‚’è€ƒæ…®ã—ãŸå›ç­”",
                    "å…·ä½“çš„ãªå¯¾å‡¦æ³•ã‚’æç¤º",
                    "ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’å«ã‚ã‚‹"
                ],
                style_modifiers={
                    "report": "ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³å ±å‘Š:",
                    "impact": "æ¥­å‹™ã¸ã®å½±éŸ¿:",
                    "action": "æ¨å¥¨å¯¾å¿œ:",
                    "priority": "å„ªå…ˆåº¦:"
                }
            )
        }
    
    def _initialize_system_formatters(self) -> Dict[str, callable]:
        """Initialize system information formatters"""
        return {
            'cpu': self._format_cpu_info,
            'memory': self._format_memory_info,
            'disk': self._format_disk_info,
            'processes': self._format_process_info,
            'network': self._format_network_info,
            'battery': self._format_battery_info,
            'wifi': self._format_wifi_info,
            'apps': self._format_running_apps_info,
            'disk_details': self._format_disk_details_info,
            'dev_tools': self._format_dev_tools_info,
            'thermal': self._format_thermal_info,
            'general': self._format_general_info
        }
    
    def _initialize_conversation_patterns(self) -> Dict[str, List[str]]:
        """Initialize conversation patterns for context awareness"""
        return {
            'greetings': [
                'ã“ã‚“ã«ã¡ã¯', 'ãŠã¯ã‚ˆã†', 'ã“ã‚“ã°ã‚“ã¯', 'ã¯ã˜ã‚ã¾ã—ã¦',
                'hello', 'hi', 'hey'
            ],
            'status_requests': [
                'çŠ¶æ…‹', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'æ§˜å­', 'èª¿å­', 'å…·åˆ',
                'status', 'condition', 'how'
            ],
            'performance_concerns': [
                'é…ã„', 'é‡ã„', 'å‹•ã‹ãªã„', 'å•é¡Œ', 'ã‚¨ãƒ©ãƒ¼',
                'slow', 'heavy', 'problem', 'error', 'issue'
            ],
            'resource_queries': [
                'CPU', 'ãƒ¡ãƒ¢ãƒª', 'ãƒ‡ã‚£ã‚¹ã‚¯', 'ãƒ—ãƒ­ã‚»ã‚¹', 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯',
                'memory', 'disk', 'process', 'network'
            ],
            'battery_queries': [
                'ãƒãƒƒãƒ†ãƒªãƒ¼', 'é›»æ± ', 'å……é›»', 'æ®‹é‡', 'ã‚ã¨', 'æ™‚é–“',
                'battery', 'power', 'charge', 'remaining'
            ],
            'wifi_queries': [
                'WiFi', 'wifi', 'ãƒ¯ã‚¤ãƒ•ã‚¡ã‚¤', 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', 'æ¥ç¶š', 'ä¿¡å·',
                'é›»æ³¢', 'SSID', 'ãƒãƒ£ãƒ³ãƒãƒ«', 'é€Ÿåº¦', 'network', 'wireless',
                'signal', 'connection', 'internet'
            ],
            'app_queries': [
                'ã‚¢ãƒ—ãƒª', 'ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³', 'é–‹ã„ã¦ã‚‹', 'å®Ÿè¡Œä¸­', 'å‹•ã„ã¦ã‚‹',
                'ãƒ—ãƒ­ã‚°ãƒ©ãƒ ', 'ã‚½ãƒ•ãƒˆ', 'app', 'application', 'running',
                'open', 'program', 'software', 'Chrome', 'Safari', 'Finder'
            ],
            'disk_detail_queries': [
                'ãƒ‡ã‚£ã‚¹ã‚¯è©³ç´°', 'ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³', 'å¤–ä»˜ã‘', 'ãƒ‰ãƒ©ã‚¤ãƒ–', 'ãƒœãƒªãƒ¥ãƒ¼ãƒ ',
                'ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è©³ç´°', 'HDD', 'SSD', 'USB', 'disk details', 'partition',
                'external', 'drive', 'volume', 'storage details', 'Volumes'
            ],
            'dev_tools_queries': [
                'é–‹ç™ºãƒ„ãƒ¼ãƒ«', 'é–‹ç™ºç’°å¢ƒ', 'Xcode', 'Git', 'Homebrew', 'Node',
                'Python', 'Docker', 'VS Code', 'brew', 'npm', 'pip',
                'development tools', 'dev tools', 'coding tools', 'programming'
            ],
            'thermal_queries': [
                'æ¸©åº¦', 'ç†±', 'ãƒ•ã‚¡ãƒ³', 'å†·å´', 'ç™ºç†±', 'ã‚µãƒ¼ãƒãƒ«', 'å›è»¢æ•°',
                'temperature', 'thermal', 'fan', 'cooling', 'heat', 'rpm',
                'æš‘ã„', 'ç†±ã„', 'hot', 'warm', 'cool'
            ]
        }
    
    def generate_system_prompt(self, 
                             user_query: str,
                             system_data: Dict[str, Any],
                             context: Optional[ConversationContext] = None,
                             focus_metric: Optional[SystemMetricType] = None) -> str:
        """
        Generate a complete Japanese prompt for the ELYZA model
        
        Args:
            user_query: User's input query
            system_data: Current system status data
            context: Conversation context for personalization
            focus_metric: Specific metric to focus on
            
        Returns:
            Complete formatted prompt string
        """
        if context is None:
            context = ConversationContext()
        
        # Determine appropriate style based on query and context
        style = self._determine_prompt_style(user_query, context)
        template = self.templates[style]
        
        # Auto-detect focus metric if not provided
        if focus_metric is None:
            focus_metric = self._detect_query_focus(user_query)
        
        # Format system information
        system_info = self._format_system_information(system_data, style, focus_metric)
        
        # Build conversation context
        conversation_context = self._build_conversation_context(context)
        
        # Generate the complete prompt
        prompt_parts = [
            template.system_role,
            "",
            template.context_format.format(system_info=system_info),
        ]
        
        # Add conversation history if available
        if conversation_context:
            prompt_parts.extend([
                "ä¼šè©±å±¥æ­´:",
                conversation_context,
                ""
            ])
        
        # Add response guidelines
        guidelines = "å›ç­”æ™‚ã®æ³¨æ„ç‚¹:\n" + "\n".join(f"- {guideline}" for guideline in template.response_guidelines)
        prompt_parts.extend([guidelines, ""])
        
        # Add user query
        prompt_parts.append(template.user_query_format.format(query=user_query))
        
        # Add response starter
        prompt_parts.append("ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: ")
        
        return "\n".join(prompt_parts)
    
    def _determine_prompt_style(self, user_query: str, context: ConversationContext) -> PromptStyle:
        """Determine the most appropriate prompt style based on query and context"""
        query_lower = user_query.lower()
        
        # Check for technical keywords
        technical_keywords = ['è©³ç´°', 'ã‚¹ãƒšãƒƒã‚¯', 'æŠ€è¡“', 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹', 'ãƒ¡ãƒˆãƒªã‚¯ã‚¹', 'ãƒ­ã‚°']
        if any(keyword in query_lower for keyword in technical_keywords):
            return PromptStyle.TECHNICAL
        
        # Check for professional context
        professional_keywords = ['ãƒ¬ãƒãƒ¼ãƒˆ', 'å ±å‘Š', 'ãƒ“ã‚¸ãƒã‚¹', 'æ¥­å‹™', 'ä¼šç¤¾']
        if any(keyword in query_lower for keyword in professional_keywords):
            return PromptStyle.PROFESSIONAL
        
        # Check for casual indicators
        casual_keywords = ['ã©ã†', 'ãªã‚“ã‹', 'ã¡ã‚‡ã£ã¨', 'ğŸ˜Š', 'ğŸ‘']
        if any(keyword in query_lower for keyword in casual_keywords):
            return PromptStyle.CASUAL
        
        # Default to user's preferred style or friendly
        return context.preferred_style
    
    def _format_system_information(self, 
                                 system_data: Dict[str, Any], 
                                 style: PromptStyle,
                                 focus_metric: Optional[SystemMetricType] = None) -> str:
        """Format system information according to style and focus"""
        formatted_parts = []
        
        if focus_metric:
            # Focus on specific metric
            if focus_metric.value in self.system_formatters:
                formatter = self.system_formatters[focus_metric.value]
                formatted_parts.append(formatter(system_data, style))
        else:
            # Include all relevant system information
            for metric_type, formatter in self.system_formatters.items():
                if metric_type != 'general':  # General is used for overview
                    formatted_info = formatter(system_data, style)
                    if formatted_info:
                        formatted_parts.append(formatted_info)
        
        return "\n".join(formatted_parts)
    
    def _detect_query_focus(self, user_query: str) -> Optional[SystemMetricType]:
        """Detect what system metric the user is asking about"""
        query_lower = user_query.lower()
        
        # Battery queries
        battery_keywords = self.conversation_patterns['battery_queries']
        if any(keyword.lower() in query_lower for keyword in battery_keywords):
            return SystemMetricType.BATTERY
        
        # WiFi queries
        wifi_keywords = self.conversation_patterns['wifi_queries']
        if any(keyword.lower() in query_lower for keyword in wifi_keywords):
            return SystemMetricType.WIFI
        
        # App queries
        app_keywords = self.conversation_patterns['app_queries']
        if any(keyword.lower() in query_lower for keyword in app_keywords):
            return SystemMetricType.APPS
        
        # Disk details queries
        disk_detail_keywords = self.conversation_patterns['disk_detail_queries']
        if any(keyword.lower() in query_lower for keyword in disk_detail_keywords):
            return SystemMetricType.DISK_DETAILS
        
        # Dev tools queries
        dev_tools_keywords = self.conversation_patterns['dev_tools_queries']
        if any(keyword.lower() in query_lower for keyword in dev_tools_keywords):
            return SystemMetricType.DEV_TOOLS
        
        # Thermal queries
        thermal_keywords = self.conversation_patterns['thermal_queries']
        if any(keyword.lower() in query_lower for keyword in thermal_keywords):
            return SystemMetricType.THERMAL
        
        # CPU queries
        cpu_keywords = ['cpu', 'ãƒ—ãƒ­ã‚»ãƒƒã‚µ', 'å‡¦ç†', 'è¨ˆç®—']
        if any(keyword in query_lower for keyword in cpu_keywords):
            return SystemMetricType.CPU
        
        # Memory queries
        memory_keywords = ['ãƒ¡ãƒ¢ãƒª', 'ram', 'è¨˜æ†¶', 'memory']
        if any(keyword in query_lower for keyword in memory_keywords):
            return SystemMetricType.MEMORY
        
        # Disk queries
        disk_keywords = ['ãƒ‡ã‚£ã‚¹ã‚¯', 'ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸', 'å®¹é‡', 'disk', 'storage']
        if any(keyword in query_lower for keyword in disk_keywords):
            return SystemMetricType.DISK
        
        # Process queries
        process_keywords = ['ãƒ—ãƒ­ã‚»ã‚¹', 'ã‚¢ãƒ—ãƒª', 'process', 'application']
        if any(keyword in query_lower for keyword in process_keywords):
            return SystemMetricType.PROCESSES
        
        # Network queries
        network_keywords = ['ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', 'é€šä¿¡', 'network', 'internet']
        if any(keyword in query_lower for keyword in network_keywords):
            return SystemMetricType.NETWORK
        
        return None
    
    def _format_cpu_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format CPU information"""
        if 'cpu_percent' not in system_data:
            return ""
        
        cpu_percent = system_data['cpu_percent']
        cpu_count = system_data.get('cpu_count', 'N/A')
        
        # Handle invalid data types
        try:
            cpu_percent = float(cpu_percent)
        except (ValueError, TypeError):
            return "CPUä½¿ç”¨ç‡: ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼"
        
        if style == PromptStyle.TECHNICAL:
            return f"CPUä½¿ç”¨ç‡: {cpu_percent:.1f}% (ã‚³ã‚¢æ•°: {cpu_count})"
        elif style == PromptStyle.CASUAL:
            if cpu_percent > 80:
                return f"CPU: {cpu_percent:.1f}% - ã¡ã‚‡ã£ã¨å¿™ã—ãã†ã§ã™ã­ ğŸ˜…"
            elif cpu_percent > 50:
                return f"CPU: {cpu_percent:.1f}% - ã¾ã‚ã¾ã‚åƒã„ã¦ã¾ã™"
            else:
                return f"CPU: {cpu_percent:.1f}% - ä½™è£•ãŒã‚ã‚Šã¾ã™ã­ ğŸ‘"
        else:
            return f"CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%"
    
    def _format_memory_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format memory information"""
        if 'memory_percent' not in system_data:
            return ""
        
        memory_percent = system_data['memory_percent']
        memory_used = system_data.get('memory_used', 0)
        memory_total = system_data.get('memory_total', 0)
        
        # Handle invalid data types
        try:
            memory_percent = float(memory_percent) if memory_percent is not None else 0.0
            memory_used = float(memory_used) if memory_used is not None else 0.0
            memory_total = float(memory_total) if memory_total is not None else 0.0
        except (ValueError, TypeError):
            return "ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼"
        
        if memory_total > 0:
            used_gb = memory_used / (1024**3)
            total_gb = memory_total / (1024**3)
            
            if style == PromptStyle.TECHNICAL:
                return f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {used_gb:.1f}GB / {total_gb:.1f}GB ({memory_percent:.1f}%)"
            elif style == PromptStyle.CASUAL:
                if memory_percent > 85:
                    return f"ãƒ¡ãƒ¢ãƒª: {memory_percent:.1f}% - ãã‚ãã‚ã„ã£ã±ã„ã‹ã‚‚ ğŸ’­"
                elif memory_percent > 70:
                    return f"ãƒ¡ãƒ¢ãƒª: {memory_percent:.1f}% - çµæ§‹ä½¿ã£ã¦ã¾ã™ã­"
                else:
                    return f"ãƒ¡ãƒ¢ãƒª: {memory_percent:.1f}% - ã¾ã ä½™è£•ãŒã‚ã‚Šã¾ã™"
            else:
                return f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {memory_percent:.1f}% ({used_gb:.1f}GB / {total_gb:.1f}GB)"
        else:
            return f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {memory_percent:.1f}%"
    
    def _format_disk_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format disk information"""
        if 'disk_percent' not in system_data:
            return ""
        
        disk_percent = system_data['disk_percent']
        disk_used = system_data.get('disk_used', 0)
        disk_total = system_data.get('disk_total', 0)
        
        if disk_total > 0:
            used_gb = disk_used / (1024**3)
            total_gb = disk_total / (1024**3)
            
            if style == PromptStyle.TECHNICAL:
                return f"ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡: {used_gb:.1f}GB / {total_gb:.1f}GB ({disk_percent:.1f}%)"
            elif style == PromptStyle.CASUAL:
                if disk_percent > 90:
                    return f"ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent:.1f}% - ãã‚ãã‚ãŠæƒé™¤ãŒå¿…è¦ã‹ã‚‚ ğŸ§¹"
                elif disk_percent > 75:
                    return f"ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent:.1f}% - ã ã„ã¶ä½¿ã£ã¦ã¾ã™ã­"
                else:
                    return f"ãƒ‡ã‚£ã‚¹ã‚¯: {disk_percent:.1f}% - ã¾ã å¤§ä¸ˆå¤«ã§ã™"
            else:
                return f"ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {disk_percent:.1f}%"
        else:
            return f"ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {disk_percent:.1f}%"
    
    def _format_process_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format process information"""
        if 'top_processes' not in system_data or not system_data['top_processes']:
            return ""
        
        # Handle invalid data types
        try:
            if not isinstance(system_data['top_processes'], list):
                return ""
            top_processes = system_data['top_processes'][:3]  # Top 3 processes
        except (TypeError, AttributeError):
            return ""
        
        if style == PromptStyle.TECHNICAL:
            process_lines = []
            for i, proc in enumerate(top_processes, 1):
                name = proc.get('name', 'Unknown')
                cpu = proc.get('cpu_percent', 0)
                memory = proc.get('memory_percent', 0)
                process_lines.append(f"{i}. {name} (CPU: {cpu:.1f}%, Memory: {memory:.1f}%)")
            return "ä¸Šä½ãƒ—ãƒ­ã‚»ã‚¹:\n" + "\n".join(process_lines)
        
        elif style == PromptStyle.CASUAL:
            top_proc = top_processes[0]
            name = top_proc.get('name', 'Unknown')
            cpu = top_proc.get('cpu_percent', 0)
            
            if cpu > 50:
                return f"ä¸€ç•ªå¿™ã—ã„ã‚¢ãƒ—ãƒª: {name} ({cpu:.1f}%) - é ‘å¼µã£ã¦ã¾ã™ã­ï¼"
            else:
                return f"ä¸€ç•ªæ´»ç™ºãªã‚¢ãƒ—ãƒª: {name} ({cpu:.1f}%)"
        
        else:
            top_proc = top_processes[0]
            name = top_proc.get('name', 'Unknown')
            cpu = top_proc.get('cpu_percent', 0)
            return f"æœ€ã‚‚CPUã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ—ãƒ­ã‚»ã‚¹: {name} ({cpu:.1f}%)"
    
    def _format_network_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format network information"""
        if 'network_io' not in system_data:
            return ""
        
        network = system_data['network_io']
        if isinstance(network, dict):
            sent_mb = network.get('bytes_sent', 0) / (1024**2)
            recv_mb = network.get('bytes_recv', 0) / (1024**2)
            
            if style == PromptStyle.TECHNICAL:
                return f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ I/O: é€ä¿¡ {sent_mb:.1f}MB, å—ä¿¡ {recv_mb:.1f}MB"
            elif style == PromptStyle.CASUAL:
                total_mb = sent_mb + recv_mb
                if total_mb > 1000:
                    return f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: {total_mb:.0f}MB - ã‚ˆãé€šä¿¡ã—ã¦ã¾ã™ã­ ğŸ“¡"
                else:
                    return f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: {total_mb:.0f}MB"
            else:
                return f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡é‡: é€ä¿¡ {sent_mb:.1f}MB, å—ä¿¡ {recv_mb:.1f}MB"
        
        return ""
    
    def _format_battery_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format battery information"""
        battery_data = system_data.get('battery')
        if not battery_data:
            return ""
        
        percent = battery_data.get('percent')
        power_plugged = battery_data.get('power_plugged')
        secsleft = battery_data.get('secsleft')
        status = battery_data.get('status', 'unknown')
        
        if percent is None:
            return ""
        
        # Format based on style
        if style == PromptStyle.CASUAL:
            battery_emoji = "ğŸ”‹" if not power_plugged else "ğŸ”Œ"
            status_text = ""
            
            if power_plugged:
                if percent >= 100:
                    status_text = "ãƒ•ãƒ«å……é›»å®Œäº†ï¼"
                else:
                    status_text = f"å……é›»ä¸­ ({percent:.0f}%)"
            else:
                status_text = f"ãƒãƒƒãƒ†ãƒªãƒ¼é§†å‹• ({percent:.0f}%)"
                if secsleft and secsleft > 0:
                    hours = secsleft // 3600
                    minutes = (secsleft % 3600) // 60
                    if hours > 0:
                        status_text += f" - ã‚ã¨ç´„{hours}æ™‚é–“{minutes}åˆ†"
                    else:
                        status_text += f" - ã‚ã¨ç´„{minutes}åˆ†"
            
            return f"{battery_emoji} {status_text}"
            
        elif style == PromptStyle.TECHNICAL:
            status_details = []
            status_details.append(f"ãƒãƒƒãƒ†ãƒªãƒ¼æ®‹é‡: {percent:.1f}%")
            status_details.append(f"é›»æºæ¥ç¶š: {'ã¯ã„' if power_plugged else 'ã„ã„ãˆ'}")
            status_details.append(f"çŠ¶æ…‹: {status}")
            
            if secsleft and secsleft > 0:
                hours = secsleft // 3600
                minutes = (secsleft % 3600) // 60
                status_details.append(f"æ¨å®šæ®‹ã‚Šæ™‚é–“: {hours}æ™‚é–“{minutes}åˆ†")
            
            return " | ".join(status_details)
            
        else:  # FRIENDLY or PROFESSIONAL
            if power_plugged:
                if percent >= 100:
                    return f"ãƒãƒƒãƒ†ãƒªãƒ¼ã¯æº€å……é›»ã§ã™ ({percent:.0f}%)"
                else:
                    return f"å……é›»ä¸­ã§ã™ ({percent:.0f}%)"
            else:
                base_text = f"ãƒãƒƒãƒ†ãƒªãƒ¼æ®‹é‡ã¯{percent:.0f}%ã§ã™"
                if secsleft and secsleft > 0:
                    hours = secsleft // 3600
                    minutes = (secsleft % 3600) // 60
                    if hours > 0:
                        base_text += f"ã€‚ã‚ã¨ç´„{hours}æ™‚é–“{minutes}åˆ†ä½¿ç”¨å¯èƒ½ã§ã™"
                    else:
                        base_text += f"ã€‚ã‚ã¨ç´„{minutes}åˆ†ä½¿ç”¨å¯èƒ½ã§ã™"
                return base_text
    
    def _format_wifi_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format WiFi information"""
        wifi_data = system_data.get('wifi')
        if not wifi_data:
            return ""
        
        is_connected = wifi_data.get('is_connected', False)
        ssid = wifi_data.get('ssid')
        signal_strength = wifi_data.get('signal_strength')
        signal_quality = wifi_data.get('signal_quality', 'unknown')
        channel = wifi_data.get('channel')
        frequency = wifi_data.get('frequency')
        security = wifi_data.get('security')
        link_speed = wifi_data.get('link_speed')
        
        if not is_connected or not ssid:
            if style == PromptStyle.CASUAL:
                return "ğŸ“¶âŒ WiFiã«æ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            else:
                return "WiFi: æœªæ¥ç¶š"
        
        # Format based on style
        if style == PromptStyle.CASUAL:
            wifi_emoji = "ğŸ“¶"
            quality_emoji = {
                'excellent': 'ğŸŸ¢',
                'good': 'ğŸŸ¡',
                'fair': 'ğŸŸ ',
                'poor': 'ğŸ”´',
                'very_poor': 'ğŸ”´',
                'unknown': 'âšª'
            }.get(signal_quality, 'âšª')
            
            base_text = f"{wifi_emoji} ã€Œ{ssid}ã€ã«æ¥ç¶šä¸­"
            
            if signal_strength is not None:
                base_text += f" {quality_emoji} {signal_strength}dBm"
            
            if channel:
                base_text += f" (ch.{channel})"
                
            return base_text
            
        elif style == PromptStyle.TECHNICAL:
            details = []
            details.append(f"SSID: {ssid}")
            
            if signal_strength is not None:
                details.append(f"ä¿¡å·å¼·åº¦: {signal_strength}dBm ({signal_quality})")
            
            if channel and frequency:
                details.append(f"ãƒãƒ£ãƒ³ãƒãƒ«: {channel} ({frequency}GHz)")
            elif channel:
                details.append(f"ãƒãƒ£ãƒ³ãƒãƒ«: {channel}")
            
            if security:
                details.append(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: {security}")
            
            if link_speed:
                details.append(f"ãƒªãƒ³ã‚¯é€Ÿåº¦: {link_speed}Mbps")
            
            return " | ".join(details)
            
        else:  # FRIENDLY or PROFESSIONAL
            base_text = f"WiFiãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€Œ{ssid}ã€ã«æ¥ç¶šä¸­ã§ã™"
            
            # Add signal quality description
            quality_descriptions = {
                'excellent': 'ä¿¡å·å¼·åº¦ã¯éå¸¸ã«è‰¯å¥½',
                'good': 'ä¿¡å·å¼·åº¦ã¯è‰¯å¥½',
                'fair': 'ä¿¡å·å¼·åº¦ã¯æ™®é€š',
                'poor': 'ä¿¡å·å¼·åº¦ã¯å¼±ã‚',
                'very_poor': 'ä¿¡å·å¼·åº¦ã¯éå¸¸ã«å¼±ã„',
                'unknown': 'ä¿¡å·å¼·åº¦ã¯ä¸æ˜'
            }
            
            if signal_quality in quality_descriptions:
                base_text += f"ã€‚{quality_descriptions[signal_quality]}"
                if signal_strength is not None:
                    base_text += f"ï¼ˆ{signal_strength}dBmï¼‰"
                base_text += "ã§ã™"
            
            # Add additional info for professional style
            if style == PromptStyle.PROFESSIONAL:
                additional_info = []
                if channel:
                    additional_info.append(f"ãƒãƒ£ãƒ³ãƒãƒ«{channel}")
                if frequency:
                    additional_info.append(f"{frequency}GHzå¸¯")
                if link_speed:
                    additional_info.append(f"{link_speed}Mbps")
                
                if additional_info:
                    base_text += f"ã€‚{', '.join(additional_info)}ã§å‹•ä½œä¸­ã§ã™"
            
            return base_text
    
    def _format_running_apps_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format running applications information"""
        apps_data = system_data.get('running_apps', [])
        if not apps_data:
            return ""
        
        # Limit to top apps to avoid overwhelming the model
        top_apps = apps_data[:8]  # Show top 8 apps
        
        if style == PromptStyle.CASUAL:
            if len(top_apps) == 0:
                return "ğŸ–¥ï¸ ã‚¢ãƒ—ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
            app_list = []
            for app in top_apps[:5]:  # Show top 5 for casual
                cpu = app.get('cpu_percent', 0)
                memory_mb = app.get('memory_mb', 0)
                name = app.get('name', 'Unknown')
                
                if cpu > 5:  # Only show apps using significant CPU
                    app_list.append(f"â€¢ {name} (CPU: {cpu:.1f}%)")
                elif memory_mb > 100:  # Or using significant memory
                    app_list.append(f"â€¢ {name} (ãƒ¡ãƒ¢ãƒª: {memory_mb:.0f}MB)")
                else:
                    app_list.append(f"â€¢ {name}")
            
            if app_list:
                return f"ğŸ–¥ï¸ å®Ÿè¡Œä¸­ã®ã‚¢ãƒ—ãƒª:\n" + "\n".join(app_list[:3])
            else:
                return f"ğŸ–¥ï¸ {len(top_apps)}å€‹ã®ã‚¢ãƒ—ãƒªãŒå®Ÿè¡Œä¸­"
                
        elif style == PromptStyle.TECHNICAL:
            details = []
            for app in top_apps:
                name = app.get('name', 'Unknown')
                cpu = app.get('cpu_percent', 0)
                memory_mb = app.get('memory_mb', 0)
                memory_percent = app.get('memory_percent', 0)
                pid = app.get('pid', 0)
                status = app.get('status', 'unknown')
                
                details.append(f"{name} (PID:{pid}): CPU {cpu:.1f}%, ãƒ¡ãƒ¢ãƒª {memory_mb:.0f}MB ({memory_percent:.1f}%), {status}")
            
            return "å®Ÿè¡Œä¸­ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³:\n" + "\n".join(details)
            
        else:  # FRIENDLY or PROFESSIONAL
            if len(top_apps) == 0:
                return "ç¾åœ¨å®Ÿè¡Œä¸­ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“"
            
            # Focus on resource-heavy apps
            heavy_apps = [app for app in top_apps if app.get('cpu_percent', 0) > 3 or app.get('memory_mb', 0) > 50]
            
            if heavy_apps:
                app_descriptions = []
                for app in heavy_apps[:4]:
                    name = app.get('name', 'Unknown')
                    cpu = app.get('cpu_percent', 0)
                    memory_mb = app.get('memory_mb', 0)
                    
                    if cpu > 10:
                        app_descriptions.append(f"{name}ï¼ˆCPUä½¿ç”¨ç‡ {cpu:.1f}%ï¼‰")
                    elif memory_mb > 200:
                        app_descriptions.append(f"{name}ï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ {memory_mb:.0f}MBï¼‰")
                    else:
                        app_descriptions.append(f"{name}")
                
                base_text = f"ç¾åœ¨ {len(top_apps)}å€‹ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™"
                if app_descriptions:
                    base_text += f"ã€‚ä¸»è¦ãªã‚¢ãƒ—ãƒª: {', '.join(app_descriptions)}"
                
                return base_text
            else:
                return f"ç¾åœ¨ {len(top_apps)}å€‹ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œä¸­ã§ã™ï¼ˆè»½é‡ãªä½¿ç”¨çŠ¶æ³ï¼‰"
    
    def _format_disk_details_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format disk details information"""
        disk_data = system_data.get('disk_details', [])
        if not disk_data:
            return ""
        
        if style == PromptStyle.CASUAL:
            if len(disk_data) == 0:
                return "ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
            disk_list = []
            for disk in disk_data[:4]:  # Show top 4 disks
                label = disk.get('label') or disk.get('mountpoint', 'Unknown')
                total_gb = disk.get('total_gb', 0)
                used_gb = disk.get('used_gb', 0)
                percent = disk.get('percent', 0)
                is_removable = disk.get('is_removable', False)
                
                icon = "ğŸ”Œ" if is_removable else "ğŸ’¾"
                
                if total_gb > 1000:  # > 1TB
                    size_text = f"{total_gb/1000:.1f}TB"
                else:
                    size_text = f"{total_gb:.0f}GB"
                
                disk_list.append(f"{icon} {label}: {used_gb:.0f}GB/{size_text} ({percent:.0f}%)")
            
            return "ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯æƒ…å ±:\n" + "\n".join(disk_list)
            
        elif style == PromptStyle.TECHNICAL:
            details = []
            for disk in disk_data:
                device = disk.get('device', 'Unknown')
                mountpoint = disk.get('mountpoint', 'Unknown')
                fstype = disk.get('fstype', 'Unknown')
                total_gb = disk.get('total_gb', 0)
                used_gb = disk.get('used_gb', 0)
                free_gb = disk.get('free_gb', 0)
                percent = disk.get('percent', 0)
                is_system = disk.get('is_system', False)
                is_removable = disk.get('is_removable', False)
                
                disk_type = "ã‚·ã‚¹ãƒ†ãƒ " if is_system else ("å¤–ä»˜ã‘" if is_removable else "å†…è”µ")
                
                details.append(f"{device} ({mountpoint}): {fstype}, {used_gb:.1f}GB/{total_gb:.1f}GB ({percent:.1f}%), ç©ºã{free_gb:.1f}GB, {disk_type}")
            
            return "ãƒ‡ã‚£ã‚¹ã‚¯è©³ç´°æƒ…å ±:\n" + "\n".join(details)
            
        else:  # FRIENDLY or PROFESSIONAL
            if len(disk_data) == 0:
                return "ãƒ‡ã‚£ã‚¹ã‚¯æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
            
            # Separate system and external disks
            system_disks = [d for d in disk_data if d.get('is_system', False)]
            external_disks = [d for d in disk_data if d.get('is_removable', False)]
            other_disks = [d for d in disk_data if not d.get('is_system', False) and not d.get('is_removable', False)]
            
            result_parts = []
            
            # System disks
            if system_disks:
                for disk in system_disks[:2]:  # Show top 2 system disks
                    label = disk.get('label') or 'ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚£ã‚¹ã‚¯'
                    total_gb = disk.get('total_gb', 0)
                    used_gb = disk.get('used_gb', 0)
                    free_gb = disk.get('free_gb', 0)
                    percent = disk.get('percent', 0)
                    
                    if total_gb > 1000:
                        size_text = f"{total_gb/1000:.1f}TB"
                        used_text = f"{used_gb/1000:.1f}TB"
                        free_text = f"{free_gb/1000:.1f}TB"
                    else:
                        size_text = f"{total_gb:.0f}GB"
                        used_text = f"{used_gb:.0f}GB"
                        free_text = f"{free_gb:.0f}GB"
                    
                    result_parts.append(f"ğŸ’¾ {label}: {used_text}/{size_text}ä½¿ç”¨ä¸­ ({percent:.0f}%), ç©ºãå®¹é‡{free_text}")
            
            # External disks
            if external_disks:
                ext_names = []
                for disk in external_disks[:3]:  # Show top 3 external disks
                    label = disk.get('label') or 'å¤–ä»˜ã‘ãƒ‡ã‚£ã‚¹ã‚¯'
                    total_gb = disk.get('total_gb', 0)
                    percent = disk.get('percent', 0)
                    
                    if total_gb > 1000:
                        size_text = f"{total_gb/1000:.1f}TB"
                    else:
                        size_text = f"{total_gb:.0f}GB"
                    
                    ext_names.append(f"{label}({size_text}, {percent:.0f}%ä½¿ç”¨)")
                
                if ext_names:
                    result_parts.append(f"ğŸ”Œ å¤–ä»˜ã‘ãƒ‡ã‚£ã‚¹ã‚¯: {', '.join(ext_names)}")
            
            # Other disks
            if other_disks and not system_disks and not external_disks:
                for disk in other_disks[:2]:
                    label = disk.get('label') or disk.get('mountpoint', 'ãƒ‡ã‚£ã‚¹ã‚¯')
                    total_gb = disk.get('total_gb', 0)
                    percent = disk.get('percent', 0)
                    
                    if total_gb > 1000:
                        size_text = f"{total_gb/1000:.1f}TB"
                    else:
                        size_text = f"{total_gb:.0f}GB"
                    
                    result_parts.append(f"ğŸ’¿ {label}: {size_text} ({percent:.0f}%ä½¿ç”¨)")
            
            if result_parts:
                return "\n".join(result_parts)
            else:
                return f"{len(disk_data)}å€‹ã®ãƒ‡ã‚£ã‚¹ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    
    def _format_dev_tools_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format development tools information"""
        dev_tools_data = system_data.get('dev_tools', [])
        if not dev_tools_data:
            return ""
        
        installed_tools = [tool for tool in dev_tools_data if tool.get('is_installed', False)]
        not_installed_tools = [tool for tool in dev_tools_data if not tool.get('is_installed', False)]
        
        if style == PromptStyle.CASUAL:
            if not installed_tools:
                return "âš™ï¸ é–‹ç™ºãƒ„ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            
            tool_list = []
            for tool in installed_tools[:5]:  # Show top 5 tools
                name = tool.get('name', 'Unknown')
                version = tool.get('version', '')
                is_running = tool.get('is_running', False)
                
                status_icon = "ğŸŸ¢" if is_running else "âšª"
                version_text = f" v{version}" if version else ""
                
                tool_list.append(f"{status_icon} {name}{version_text}")
            
            return "âš™ï¸ é–‹ç™ºãƒ„ãƒ¼ãƒ«:\n" + "\n".join(tool_list)
            
        elif style == PromptStyle.TECHNICAL:
            details = []
            for tool in dev_tools_data:
                name = tool.get('name', 'Unknown')
                version = tool.get('version', 'N/A')
                path = tool.get('path', 'N/A')
                is_installed = tool.get('is_installed', False)
                is_running = tool.get('is_running', False)
                additional_info = tool.get('additional_info', {})
                
                status = "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿" if is_installed else "æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
                if is_installed and is_running:
                    status += " (å®Ÿè¡Œä¸­)"
                
                detail_line = f"{name}: {version}, {status}, ãƒ‘ã‚¹: {path}"
                
                # Add additional info
                if additional_info:
                    extra_info = []
                    for key, value in additional_info.items():
                        if key == 'user_name':
                            extra_info.append(f"Git User: {value}")
                        elif key == 'npm_version':
                            extra_info.append(f"npm: {value}")
                        elif key == 'pip_version':
                            extra_info.append(f"pip: {value}")
                    
                    if extra_info:
                        detail_line += f" ({', '.join(extra_info)})"
                
                details.append(detail_line)
            
            return "é–‹ç™ºãƒ„ãƒ¼ãƒ«è©³ç´°:\n" + "\n".join(details)
            
        else:  # FRIENDLY or PROFESSIONAL
            if not installed_tools:
                return "é–‹ç™ºãƒ„ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            # Group by status
            running_tools = [t for t in installed_tools if t.get('is_running', False)]
            installed_only = [t for t in installed_tools if not t.get('is_running', False)]
            
            result_parts = []
            
            # Installed and running tools
            if running_tools:
                running_names = []
                for tool in running_tools[:3]:
                    name = tool.get('name', 'Unknown')
                    version = tool.get('version', '')
                    version_text = f" v{version}" if version else ""
                    running_names.append(f"{name}{version_text}")
                
                result_parts.append(f"ğŸŸ¢ å®Ÿè¡Œä¸­: {', '.join(running_names)}")
            
            # Installed but not running tools
            if installed_only:
                installed_names = []
                for tool in installed_only[:4]:
                    name = tool.get('name', 'Unknown')
                    version = tool.get('version', '')
                    version_text = f" v{version}" if version else ""
                    installed_names.append(f"{name}{version_text}")
                
                result_parts.append(f"âšª ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿: {', '.join(installed_names)}")
            
            # Not installed tools (only show a few important ones)
            important_missing = []
            for tool in not_installed_tools:
                name = tool.get('name', '')
                if name in ['Xcode', 'Git', 'Homebrew', 'Docker']:
                    important_missing.append(name)
            
            if important_missing and len(important_missing) <= 2:
                result_parts.append(f"âŒ æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: {', '.join(important_missing)}")
            
            if result_parts:
                return "\n".join(result_parts)
            else:
                return f"{len(installed_tools)}å€‹ã®é–‹ç™ºãƒ„ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã§ã™"
    
    def _format_thermal_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format thermal and fan information"""
        thermal_data = system_data.get('thermal_info')
        if not thermal_data:
            return ""
        
        cpu_temp = thermal_data.get('cpu_temperature')
        gpu_temp = thermal_data.get('gpu_temperature')
        fan_speeds = thermal_data.get('fan_speeds', [])
        thermal_state = thermal_data.get('thermal_state', 'unknown')
        power_metrics = thermal_data.get('power_metrics', {})
        
        if style == PromptStyle.CASUAL:
            if not cpu_temp and not gpu_temp and not fan_speeds:
                return "ğŸŒ¡ï¸ æ¸©åº¦æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“"
            
            temp_parts = []
            if cpu_temp:
                temp_emoji = "ğŸ”¥" if cpu_temp > 80 else "ğŸŒ¡ï¸" if cpu_temp > 60 else "â„ï¸"
                temp_parts.append(f"{temp_emoji} CPU: {cpu_temp:.0f}Â°C")
            
            if gpu_temp:
                temp_emoji = "ğŸ”¥" if gpu_temp > 80 else "ğŸŒ¡ï¸" if gpu_temp > 60 else "â„ï¸"
                temp_parts.append(f"{temp_emoji} GPU: {gpu_temp:.0f}Â°C")
            
            if fan_speeds:
                fan_info = []
                for fan in fan_speeds[:2]:  # Show top 2 fans
                    name = fan.get('name', 'Fan')
                    rpm = fan.get('rpm', 0)
                    fan_info.append(f"ğŸ’¨ {name}: {rpm}rpm")
                temp_parts.extend(fan_info)
            
            if temp_parts:
                return "\n".join(temp_parts)
            else:
                return f"ğŸŒ¡ï¸ ã‚·ã‚¹ãƒ†ãƒ æ¸©åº¦: {thermal_state}"
                
        elif style == PromptStyle.TECHNICAL:
            details = []
            
            if cpu_temp:
                details.append(f"CPUæ¸©åº¦: {cpu_temp:.1f}Â°C")
            if gpu_temp:
                details.append(f"GPUæ¸©åº¦: {gpu_temp:.1f}Â°C")
            
            details.append(f"ã‚µãƒ¼ãƒãƒ«çŠ¶æ…‹: {thermal_state}")
            
            if fan_speeds:
                fan_details = []
                for fan in fan_speeds:
                    name = fan.get('name', 'Unknown Fan')
                    rpm = fan.get('rpm', 0)
                    fan_details.append(f"{name}: {rpm}rpm")
                details.append(f"ãƒ•ã‚¡ãƒ³: {', '.join(fan_details)}")
            
            if power_metrics and power_metrics.get('power_source'):
                details.append(f"é›»æº: {power_metrics['power_source']}")
            
            return "ã‚µãƒ¼ãƒãƒ«æƒ…å ±: " + " | ".join(details)
            
        else:  # FRIENDLY or PROFESSIONAL
            if not cpu_temp and not gpu_temp and not fan_speeds:
                return "æ¸©åº¦ãƒ»ãƒ•ã‚¡ãƒ³æƒ…å ±ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆmacOSã§ã¯ç®¡ç†è€…æ¨©é™ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ï¼‰"
            
            result_parts = []
            
            # Temperature info
            temp_info = []
            if cpu_temp:
                if cpu_temp > 85:
                    temp_status = "é«˜æ¸©"
                    temp_icon = "ğŸ”¥"
                elif cpu_temp > 70:
                    temp_status = "ã‚„ã‚„é«˜æ¸©"
                    temp_icon = "ğŸŒ¡ï¸"
                elif cpu_temp > 50:
                    temp_status = "æ­£å¸¸"
                    temp_icon = "âœ…"
                else:
                    temp_status = "ä½æ¸©"
                    temp_icon = "â„ï¸"
                
                temp_info.append(f"{temp_icon} CPUæ¸©åº¦: {cpu_temp:.0f}Â°C ({temp_status})")
            
            if gpu_temp:
                if gpu_temp > 85:
                    temp_status = "é«˜æ¸©"
                    temp_icon = "ğŸ”¥"
                elif gpu_temp > 70:
                    temp_status = "ã‚„ã‚„é«˜æ¸©"
                    temp_icon = "ğŸŒ¡ï¸"
                else:
                    temp_status = "æ­£å¸¸"
                    temp_icon = "âœ…"
                
                temp_info.append(f"{temp_icon} GPUæ¸©åº¦: {gpu_temp:.0f}Â°C ({temp_status})")
            
            if temp_info:
                result_parts.extend(temp_info)
            
            # Fan info
            if fan_speeds:
                fan_info = []
                for fan in fan_speeds:
                    name = fan.get('name', 'ãƒ•ã‚¡ãƒ³')
                    rpm = fan.get('rpm', 0)
                    
                    if rpm > 3000:
                        fan_status = "é«˜é€Ÿ"
                        fan_icon = "ğŸ’¨"
                    elif rpm > 1500:
                        fan_status = "ä¸­é€Ÿ"
                        fan_icon = "ğŸŒ€"
                    elif rpm > 500:
                        fan_status = "ä½é€Ÿ"
                        fan_icon = "ğŸ’¨"
                    else:
                        fan_status = "åœæ­¢"
                        fan_icon = "â¸ï¸"
                    
                    fan_info.append(f"{fan_icon} {name}: {rpm}rpm ({fan_status})")
                
                if fan_info:
                    result_parts.extend(fan_info)
            
            # Thermal state summary
            if thermal_state != "unknown":
                state_descriptions = {
                    'normal': 'ğŸŸ¢ ã‚·ã‚¹ãƒ†ãƒ æ¸©åº¦ã¯æ­£å¸¸ã§ã™',
                    'warm': 'ğŸŸ¡ ã‚·ã‚¹ãƒ†ãƒ ãŒã‚„ã‚„æ¸©ã‹ããªã£ã¦ã„ã¾ã™',
                    'hot': 'ğŸ”´ ã‚·ã‚¹ãƒ†ãƒ ãŒé«˜æ¸©ã«ãªã£ã¦ã„ã¾ã™',
                    'critical': 'ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ ãŒå±é™ºãªé«˜æ¸©çŠ¶æ…‹ã§ã™'
                }
                
                if thermal_state in state_descriptions:
                    result_parts.append(state_descriptions[thermal_state])
            
            if result_parts:
                return "\n".join(result_parts)
            else:
                return "æ¸©åº¦ãƒ»ãƒ•ã‚¡ãƒ³æƒ…å ±ã®è©³ç´°ã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
    
    def _format_general_info(self, system_data: Dict[str, Any], style: PromptStyle) -> str:
        """Format general system overview"""
        timestamp = system_data.get('timestamp')
        if timestamp:
            if isinstance(timestamp, str):
                time_str = timestamp
            else:
                time_str = timestamp.strftime('%H:%M:%S')
            
            if style == PromptStyle.CASUAL:
                return f"ğŸ“Š {time_str} ç¾åœ¨ã®çŠ¶æ³"
            else:
                return f"å–å¾—æ™‚åˆ»: {time_str}"
        
        return ""
    
    def _build_conversation_context(self, context: ConversationContext) -> str:
        """Build conversation context string"""
        if not context.conversation_history:
            return ""
        
        # Get recent conversation (last 3 exchanges)
        recent_history = context.conversation_history[-6:]  # 3 exchanges = 6 messages
        
        context_lines = []
        for msg in recent_history:
            role = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if msg.get('role') == 'user' else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
            content = msg.get('content', '')[:100]  # Limit length
            if len(msg.get('content', '')) > 100:
                content += "..."
            context_lines.append(f"{role}: {content}")
        
        return "\n".join(context_lines)
    
    def create_focused_prompt(self, 
                            user_query: str,
                            system_data: Dict[str, Any],
                            metric_type: SystemMetricType,
                            context: Optional[ConversationContext] = None) -> str:
        """
        Create a prompt focused on a specific system metric
        
        Args:
            user_query: User's query
            system_data: System information
            metric_type: Type of metric to focus on
            context: Conversation context
            
        Returns:
            Focused prompt string
        """
        return self.generate_system_prompt(
            user_query=user_query,
            system_data=system_data,
            context=context,
            focus_metric=metric_type
        )
    
    def create_comparison_prompt(self,
                               user_query: str,
                               current_data: Dict[str, Any],
                               previous_data: Dict[str, Any],
                               context: Optional[ConversationContext] = None) -> str:
        """
        Create a prompt that compares current and previous system states
        
        Args:
            user_query: User's query
            current_data: Current system data
            previous_data: Previous system data
            context: Conversation context
            
        Returns:
            Comparison prompt string
        """
        if context is None:
            context = ConversationContext()
        
        style = self._determine_prompt_style(user_query, context)
        template = self.templates[style]
        
        # Format current and previous data
        current_info = self._format_system_information(current_data, style)
        previous_info = self._format_system_information(previous_data, style)
        
        # Create comparison context
        comparison_context = f"ç¾åœ¨ã®çŠ¶æ…‹:\n{current_info}\n\nä»¥å‰ã®çŠ¶æ…‹:\n{previous_info}\n"
        
        # Build conversation context
        conversation_context = self._build_conversation_context(context)
        
        # Generate comparison prompt
        prompt_parts = [
            template.system_role + " ç¾åœ¨ã®çŠ¶æ…‹ã¨ä»¥å‰ã®çŠ¶æ…‹ã‚’æ¯”è¼ƒã—ã¦ã€å¤‰åŒ–ã‚„å‚¾å‘ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
            "",
            comparison_context,
        ]
        
        if conversation_context:
            prompt_parts.extend([
                "ä¼šè©±å±¥æ­´:",
                conversation_context,
                ""
            ])
        
        prompt_parts.extend([
            "æ¯”è¼ƒåˆ†æã®æ³¨æ„ç‚¹:",
            "- é‡è¦ãªå¤‰åŒ–ã‚’ç‰¹å®šã™ã‚‹",
            "- æ”¹å–„ç‚¹ã‚„æ‚ªåŒ–ç‚¹ã‚’æ˜ç¢ºã«ã™ã‚‹", 
            "- å¿…è¦ã«å¿œã˜ã¦å¯¾å‡¦æ³•ã‚’ææ¡ˆã™ã‚‹",
            "",
            template.user_query_format.format(query=user_query),
            "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: "
        ])
        
        return "\n".join(prompt_parts)
    
    def extract_query_intent(self, user_query: str) -> Dict[str, Any]:
        """
        Extract intent and entities from user query
        
        Args:
            user_query: User's input query
            
        Returns:
            Dictionary with intent and extracted information
        """
        query_lower = user_query.lower()
        
        intent_info = {
            'primary_intent': 'general_inquiry',
            'metric_focus': None,
            'urgency_level': 'normal',
            'response_type': 'informative',
            'entities': []
        }
        
        # Detect metric focus
        for pattern_type, keywords in self.conversation_patterns.items():
            for keyword in keywords:
                if keyword.lower() in query_lower:
                    if pattern_type == 'resource_queries':
                        if 'cpu' in keyword.lower():
                            intent_info['metric_focus'] = SystemMetricType.CPU
                        elif 'ãƒ¡ãƒ¢ãƒª' in keyword or 'memory' in keyword.lower():
                            intent_info['metric_focus'] = SystemMetricType.MEMORY
                        elif 'ãƒ‡ã‚£ã‚¹ã‚¯' in keyword or 'disk' in keyword.lower():
                            intent_info['metric_focus'] = SystemMetricType.DISK
                        elif 'ãƒ—ãƒ­ã‚»ã‚¹' in keyword or 'process' in keyword.lower():
                            intent_info['metric_focus'] = SystemMetricType.PROCESSES
                        elif 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯' in keyword or 'network' in keyword.lower():
                            intent_info['metric_focus'] = SystemMetricType.NETWORK
                    
                    intent_info['entities'].append({
                        'type': pattern_type,
                        'value': keyword,
                        'category': pattern_type
                    })
        
        # Detect urgency
        urgent_keywords = ['ç·Šæ€¥', 'æ€¥ã„ã§', 'å•é¡Œ', 'ã‚¨ãƒ©ãƒ¼', 'å‹•ã‹ãªã„', 'é…ã„', 'é‡ã„', 'ï¼', 'ã‚¯ãƒ©ãƒƒã‚·ãƒ¥', 'åœæ­¢']
        if any(keyword in query_lower for keyword in urgent_keywords):
            intent_info['urgency_level'] = 'high'
        
        # Detect response type preference
        if any(word in query_lower for word in ['è©³ã—ã', 'è©³ç´°', 'å…·ä½“çš„']):
            intent_info['response_type'] = 'detailed'
        elif any(word in query_lower for word in ['ç°¡å˜', 'è¦ç´„', 'çŸ­ã']):
            intent_info['response_type'] = 'brief'
        
        return intent_info


# Utility functions for common prompt generation scenarios
def create_status_check_prompt(system_data: Dict[str, Any], 
                             style: PromptStyle = PromptStyle.FRIENDLY) -> str:
    """Create a prompt for general status check"""
    generator = PromptGenerator()
    context = ConversationContext(preferred_style=style)
    
    return generator.generate_system_prompt(
        user_query="ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’æ•™ãˆã¦ãã ã•ã„",
        system_data=system_data,
        context=context
    )


def create_performance_analysis_prompt(system_data: Dict[str, Any],
                                     performance_issues: List[str] = None) -> str:
    """Create a prompt for performance analysis"""
    generator = PromptGenerator()
    context = ConversationContext(preferred_style=PromptStyle.TECHNICAL)
    
    query = "ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æã—ã¦ãã ã•ã„"
    if performance_issues:
        query += f"ã€‚ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã«ã¤ã„ã¦: {', '.join(performance_issues)}"
    
    return generator.generate_system_prompt(
        user_query=query,
        system_data=system_data,
        context=context
    )


def create_troubleshooting_prompt(system_data: Dict[str, Any],
                                issue_description: str) -> str:
    """Create a prompt for troubleshooting assistance"""
    generator = PromptGenerator()
    context = ConversationContext(preferred_style=PromptStyle.PROFESSIONAL)
    
    query = f"æ¬¡ã®å•é¡Œã«ã¤ã„ã¦å¯¾å‡¦æ³•ã‚’æ•™ãˆã¦ãã ã•ã„: {issue_description}"
    
    return generator.generate_system_prompt(
        user_query=query,
        system_data=system_data,
        context=context
    )


# Test function
async def test_prompt_generator():
    """Test function for JapanesePromptGenerator"""
    print("ğŸ§ª Testing Japanese Prompt Generator")
    print("=" * 50)
    
    # Sample system data
    sample_system_data = {
        'timestamp': datetime.now(),
        'cpu_percent': 45.2,
        'cpu_count': 8,
        'memory_percent': 68.5,
        'memory_used': 11 * 1024**3,  # 11GB
        'memory_total': 16 * 1024**3,  # 16GB
        'disk_percent': 72.1,
        'disk_used': 360 * 1024**3,   # 360GB
        'disk_total': 500 * 1024**3,  # 500GB
        'top_processes': [
            {'name': 'Google Chrome', 'cpu_percent': 25.3, 'memory_percent': 15.2},
            {'name': 'Xcode', 'cpu_percent': 12.1, 'memory_percent': 8.7},
            {'name': 'Finder', 'cpu_percent': 3.2, 'memory_percent': 2.1}
        ],
        'network_io': {
            'bytes_sent': 150 * 1024**2,  # 150MB
            'bytes_recv': 300 * 1024**2   # 300MB
        }
    }
    
    generator = PromptGenerator()
    
    # Test different styles
    test_cases = [
        ("ã‚·ã‚¹ãƒ†ãƒ ã®èª¿å­ã¯ã©ã†ã§ã™ã‹ï¼Ÿ", PromptStyle.CASUAL),
        ("è©³ç´°ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™", PromptStyle.TECHNICAL),
        ("ç¾åœ¨ã®çŠ¶æ³ã‚’æ•™ãˆã¦ãã ã•ã„", PromptStyle.FRIENDLY),
        ("ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„", PromptStyle.PROFESSIONAL)
    ]
    
    for i, (query, style) in enumerate(test_cases, 1):
        print(f"\n{i}. Test Case: {style.value.upper()}")
        print("-" * 30)
        
        context = ConversationContext(
            preferred_style=style,
            user_expertise_level="intermediate",
            conversation_history=[
                {"role": "user", "content": "ã“ã‚“ã«ã¡ã¯"},
                {"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"}
            ]
        )
        
        prompt = generator.generate_system_prompt(
            user_query=query,
            system_data=sample_system_data,
            context=context
        )
        
        print(f"Query: {query}")
        print(f"Generated Prompt Length: {len(prompt)} characters")
        print(f"Preview: {prompt[:200]}...")
        
        # Test intent extraction
        intent = generator.extract_query_intent(query)
        print(f"Detected Intent: {intent['primary_intent']}")
        if intent['metric_focus']:
            print(f"Metric Focus: {intent['metric_focus'].value}")
    
    # Test focused prompts
    print(f"\n5. Test Focused Prompt (CPU)")
    print("-" * 30)
    
    focused_prompt = generator.create_focused_prompt(
        user_query="CPUã®ä½¿ç”¨çŠ¶æ³ã«ã¤ã„ã¦æ•™ãˆã¦",
        system_data=sample_system_data,
        metric_type=SystemMetricType.CPU
    )
    
    print(f"Focused Prompt Length: {len(focused_prompt)} characters")
    print(f"Preview: {focused_prompt[:200]}...")
    
    print("\nâœ… All tests completed successfully!")


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_prompt_generator())